#!rnn.py

def summary(name, x):
  """
  :param str name:
  :param tf.Tensor x: (batch,time,feature)
  """
  import tensorflow as tf
  # tf.summary.image wants [batch_size, height,  width, channels],
  # we have (batch, time, feature).
  img = tf.expand_dims(x, axis=3)  # (batch,time,feature,1)
  img = tf.transpose(img, [0, 2, 1, 3])  # (batch,feature,time,1)
  tf.summary.image(name, img, max_outputs=10)
  tf.summary.scalar("%s_max_abs" % name, tf.reduce_max(tf.abs(x)))
  mean = tf.reduce_mean(x)
  tf.summary.scalar("%s_mean" % name, mean)
  stddev = tf.sqrt(tf.reduce_mean(tf.square(x - mean)))
  tf.summary.scalar("%s_stddev" % name, stddev)
  tf.summary.histogram("%s_hist" % name, tf.reduce_max(tf.abs(x), axis=2))

def _mask(x, axis, pos, max_amount):
  """
  :param tf.Tensor x: (batch,time,feature)
  :param int axis:
  :param tf.Tensor pos: (batch,)
  :param int max_amount: inclusive
  """
  import tensorflow as tf
  ndim = x.get_shape().ndims
  n_batch = tf.shape(x)[0]
  dim = tf.shape(x)[axis]
  amount = tf.random_uniform(shape=(n_batch,), minval=1, maxval=max_amount + 1, dtype=tf.int32)
  pos2 = tf.minimum(pos + amount, dim)
  idxs = tf.expand_dims(tf.range(0, dim), 0)  # (1,dim)
  pos_bc = tf.expand_dims(pos, 1)  # (batch,1)
  pos2_bc = tf.expand_dims(pos2, 1)  # (batch,1)
  cond = tf.logical_and(tf.greater_equal(idxs, pos_bc), tf.less(idxs, pos2_bc))  # (batch,dim)
  cond = tf.reshape(cond, [tf.shape(x)[i] if i in (0, axis) else 1 for i in range(ndim)])
  from TFUtil import where_bc
  x = where_bc(cond, 0.0, x)
  return x

def random_mask(x, axis, min_num, max_num, max_dims):
  """
  :param tf.Tensor x: (batch,time,feature)
  :param int axis:
  :param int|tf.Tensor min_num:
  :param int|tf.Tensor max_num: inclusive
  :param int max_dims: inclusive
  """
  import tensorflow as tf
  n_batch = tf.shape(x)[0]
  num = tf.random_uniform(shape=(n_batch,), minval=min_num, maxval=max_num + 1, dtype=tf.int32)
  # https://github.com/tensorflow/tensorflow/issues/9260
  # https://timvieira.github.io/blog/post/2014/08/01/gumbel-max-trick-and-weighted-reservoir-sampling/
  z = -tf.log(-tf.log(tf.random_uniform((n_batch, tf.shape(x)[axis]), 0, 1)))
  _, indices = tf.nn.top_k(z, tf.reduce_max(num))
  # indices should be sorted, and of shape (batch,num), entries (int32) in [0,dim)
  # indices = tf.Print(indices, ["indices", indices, tf.shape(indices)])
  _, x = tf.while_loop(
    cond=lambda i, _: tf.less(i, tf.reduce_max(num)),
    body=lambda i, x: (
      i + 1,
      tf.where(
        tf.less(i, num),
        _mask(x, axis=axis, pos=indices[:, i], max_amount=max_dims),
        x)),
    loop_vars=(0, x))
  return x

def transform(data, network):
  x = data.placeholder
  import tensorflow as tf
  x = tf.clip_by_value(x, -3.0, 3.0)

  def get_masked():
    x_masked = x
    x_masked = random_mask(x_masked, axis=1, min_num=1, max_num=tf.maximum(tf.shape(x)[1] // 100, 1), max_dims=20)
    x_masked = random_mask(x_masked, axis=2, min_num=1, max_num=2, max_dims=40 // 5)
    return x_masked

  x = network.cond_on_train(get_masked, lambda: x)
  return x

def custom_construction_algo(idx, net_dict):
  # For debugging, use: python3 ./crnn/Pretrain.py config... Maybe set repetitions=1 below.
  StartNumLayers = 2
  InitialDimFactor = 0.5
  orig_num_lstm_layers = 0
  while "lstm%i_fw" % orig_num_lstm_layers in net_dict:
    orig_num_lstm_layers += 1
  assert orig_num_lstm_layers >= 2
  orig_red_factor = 1
  for i in range(orig_num_lstm_layers - 1):
    orig_red_factor *= net_dict["lstm%i_pool" % i]["pool_size"][0]
  net_dict["#config"] = {}
  if idx < 4:
    net_dict["#config"]["batch_size"] = 20000
  idx = max(idx - 4, 0)  # repeat first
  num_lstm_layers = idx + StartNumLayers  # idx starts at 0. start with N layers
  if num_lstm_layers > orig_num_lstm_layers:
    # Finish. This will also use label-smoothing then.
    return None
  if num_lstm_layers == 2:
    net_dict["lstm0_pool"]["pool_size"] = (orig_red_factor,)
  # Skip to num layers.
  net_dict["encoder"]["from"] = ["lstm%i_fw" % (num_lstm_layers - 1), "lstm%i_bw" % (num_lstm_layers - 1)]
  # Delete non-used lstm layers. This is not explicitly necessary but maybe nicer.
  for i in range(num_lstm_layers, orig_num_lstm_layers):
    del net_dict["lstm%i_fw" % i]
    del net_dict["lstm%i_bw" % i]
    del net_dict["lstm%i_pool" % (i - 1)]
  # Thus we have layers 0 .. (num_lstm_layers - 1).
  layer_idxs = list(range(0, num_lstm_layers))
  layers = ["lstm%i_fw" % i for i in layer_idxs] + ["lstm%i_bw" % i for i in layer_idxs]
  grow_frac = 1.0 - float(orig_num_lstm_layers - num_lstm_layers) / (orig_num_lstm_layers - StartNumLayers)
  dim_frac = InitialDimFactor + (1.0 - InitialDimFactor) * grow_frac
  for layer in layers:
    net_dict[layer]["n_out"] = int(net_dict[layer]["n_out"] * dim_frac)
    if "dropout" in net_dict[layer]:
      net_dict[layer]["dropout"] *= dim_frac
    if "L2" in net_dict[layer]:
      net_dict[layer]['L2'] *= dim_frac
  net_dict["enc_value"]["dims"] = (AttNumHeads, int(EncValuePerHeadDim * dim_frac * 0.5) * 2)
  # Use label smoothing only at the very end.
  if 'loss_opts' in net_dict["output"]["unit"]["output_prob"]:
    net_dict["output"]["unit"]["output_prob"]["loss_opts"]["label_smoothing"] = 0
  return net_dict


AttNumHeads = 1
EncValuePerHeadDim = 2048
accum_grad_multiple_step = 2
adam = True
batch_size = 20000
batching = 'random'
cache_size = '0'
cleanup_old_models = True
debug_mode = False
debug_print_layer_output_template = True
dev = { 'audio': { 'features': 'mfcc',
             'norm_mean': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/stats.mean.txt',
             'norm_std_dev': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/stats.std_dev.txt',
             'step_len': 0.01,
             'window_len': 0.025},
  'class': 'LibriSpeechCorpus',
  'fixed_random_seed': 1,
  'fixed_random_subset': 3000,
  'path': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/ogg-zips',
  'prefix': 'dev',
  'seq_ordering': 'sorted_reverse',
  'targets': { 'bpe_file': '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/bpe/train/ReturnnTrainBpeJob.GdFCt6YOja1s/output/bpe.codes',
               'class': 'BytePairEncoding',
               'seq_postfix': [0],
               'unknown_label': None,
               'vocab_file': '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/bpe/train/ReturnnTrainBpeJob.GdFCt6YOja1s/output/bpe.vocab'},
  'use_cache_manager': True,
  'use_ogg': True,
  'use_zip': True}
device = 'gpu'
eval_datasets = { 'devtrain': { 'audio': { 'features': 'mfcc',
                           'norm_mean': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/stats.mean.txt',
                           'norm_std_dev': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/stats.std_dev.txt',
                           'step_len': 0.01,
                           'window_len': 0.025},
                'class': 'LibriSpeechCorpus',
                'fixed_random_seed': 1,
                'fixed_random_subset': 3000,
                'path': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/ogg-zips',
                'prefix': 'train',
                'seq_ordering': 'sorted_reverse',
                'targets': { 'bpe_file': '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/bpe/train/ReturnnTrainBpeJob.GdFCt6YOja1s/output/bpe.codes',
                             'class': 'BytePairEncoding',
                             'seq_postfix': [0],
                             'unknown_label': None,
                             'vocab_file': '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/bpe/train/ReturnnTrainBpeJob.GdFCt6YOja1s/output/bpe.vocab'},
                'use_cache_manager': True,
                'use_ogg': True,
                'use_zip': True}}
extern_data = {'classes': {'dim': 10025, 'shape': (None,), 'sparse': True}, 'data': {'dim': 40, 'shape': (None, 40)}}
gradient_clip = 0
gradient_noise = 0.0
learning_rate = 0.0008
learning_rate_control = 'newbob_multi_epoch'
learning_rate_control_min_num_epochs_per_new_lr = 3
learning_rate_control_relative_error_relative_lr = True
learning_rate_file = 'learning_rates'
learning_rates = None
log = ['./crnn.log']
log_batch_size = True
log_verbosity = 5
max_seqs = 200
min_learning_rate = 1.6e-05
model = '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/crnn/training/CRNNTrainingJob.F41wE8LCbCl7/output/models/epoch'
multiprocessing = True
network = { 'conv0': { 'L2': 0.0001,
             'activation': None,
             'class': 'conv',
             'filter_size': (3, 3),
             'from': 'source0',
             'n_out': 32,
             'padding': 'same',
             'with_bias': True},
  'conv0p': {'class': 'pool', 'from': 'conv0', 'mode': 'max', 'padding': 'same', 'pool_size': (1, 2), 'trainable': False},
  'conv1': { 'L2': 0.0001,
             'activation': None,
             'class': 'conv',
             'filter_size': (3, 3),
             'from': 'conv0p',
             'n_out': 32,
             'padding': 'same',
             'with_bias': True},
  'conv1p': {'class': 'pool', 'from': 'conv1', 'mode': 'max', 'padding': 'same', 'pool_size': (1, 2), 'trainable': False},
  'conv_merged': {'axes': 'static', 'class': 'merge_dims', 'from': 'conv1p'},
  'ctc': { 'class': 'softmax',
           'from': 'encoder',
           'loss': 'ctc',
           'loss_opts': {'beam_width': 1, 'ctc_opts': {'ignore_longer_outputs_than_inputs': True}},
           'target': 'classes'},
  'decision': {'class': 'decide', 'from': 'output', 'loss': 'edit_distance', 'target': 'classes'},
  'enc_ctx': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'encoder', 'n_out': 1024, 'with_bias': True},
  'enc_value': {'axis': 'F', 'class': 'split_dims', 'dims': (1, 2048), 'from': 'encoder'},
  'encoder': {'class': 'copy', 'from': ['lstm5_fw', 'lstm5_bw']},
  'inv_fertility': {'activation': 'sigmoid', 'class': 'linear', 'from': 'encoder', 'n_out': 1, 'with_bias': False},
  'lstm0_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': 'conv_merged', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm0_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': 'conv_merged', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm0_pool': {'class': 'pool', 'from': ['lstm0_fw', 'lstm0_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (3,), 'trainable': False},
  'lstm1_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': 'lstm0_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm1_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': 'lstm0_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm1_pool': {'class': 'pool', 'from': ['lstm1_fw', 'lstm1_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (2,), 'trainable': False},
  'lstm2_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': 'lstm1_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm2_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': 'lstm1_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm2_pool': {'class': 'pool', 'from': ['lstm2_fw', 'lstm2_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
  'lstm3_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': 'lstm2_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm3_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': 'lstm2_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm3_pool': {'class': 'pool', 'from': ['lstm3_fw', 'lstm3_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
  'lstm4_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': 'lstm3_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm4_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': 'lstm3_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm4_pool': {'class': 'pool', 'from': ['lstm4_fw', 'lstm4_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
  'lstm5_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': 'lstm4_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm5_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': 'lstm4_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'output': { 'class': 'rec',
              'from': [],
              'max_seq_len': "max_len_from('base:encoder')",
              'target': 'classes',
              'unit': { 'accum_att_weights': { 'class': 'eval',
                                               'eval': 'source(0) + source(1) * source(2) * 0.5',
                                               'from': ['prev:accum_att_weights', 'att_weights', 'base:inv_fertility'],
                                               'out_type': {'dim': 1, 'shape': (None, 1)}},
                        'att': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'att_lstm', 'n_out': 2048},
                        'att0': {'base': 'base:enc_value', 'class': 'generic_attention', 'weights': 'att_weights'},
                        'att_lstm': {'class': 'rec', 'from': 'prev:target_embed', 'n_out': 50, 'unit': 'nativelstm2'},
                        'att_weights': {'class': 'softmax_over_spatial', 'from': 'energy'},
                        'end': {'class': 'compare', 'from': 'output', 'kind': 'equal', 'value': 0},
                        'energy': {'activation': None, 'class': 'linear', 'from': 'energy_tanh', 'n_out': 1, 'with_bias': False},
                        'energy_in': {'class': 'combine', 'from': ['base:enc_ctx', 'weight_feedback', 's_transformed'], 'kind': 'add', 'n_out': 1024},
                        'energy_tanh': {'activation': 'tanh', 'class': 'activation', 'from': 'energy_in'},
                        'output': {'beam_size': 12, 'class': 'choice', 'from': 'output_prob', 'initial_output': 0, 'target': 'classes'},
                        'output_prob': { 'L2': 0.0001,
                                         'class': 'softmax',
                                         'dropout': 0.3,
                                         'from': 'readout',
                                         'loss': 'ce',
                                         'loss_opts': {'label_smoothing': 0.1},
                                         'target': 'classes'},
                        'readout': {'class': 'reduce_out', 'from': 'readout_in', 'mode': 'max', 'num_pieces': 2},
                        'readout_in': { 'activation': None,
                                        'class': 'linear',
                                        'from': ['s', 'prev:target_embed', 'att'],
                                        'n_out': 1000,
                                        'with_bias': True},
                        's': {'L2': 0.0001, 'class': 'rnn_cell', 'from': ['prev:target_embed', 'prev:att'], 'n_out': 1000, 'unit': 'LSTMBlock'},
                        's_transformed': {'activation': None, 'class': 'linear', 'from': 's', 'n_out': 1024, 'with_bias': False},
                        'target_embed': { 'activation': None,
                                          'class': 'linear',
                                          'from': 'output',
                                          'initial_output': 0,
                                          'n_out': 621,
                                          'with_bias': False},
                        'weight_feedback': { 'activation': None,
                                             'class': 'linear',
                                             'from': 'prev:accum_att_weights',
                                             'n_out': 1024,
                                             'with_bias': False}}},
  'source': { 'class': 'eval',
              'eval': "self.network.get_config().typed_value('transform')(source(0, as_data=True), network=self.network)",
              'from': 'data'},
  'source0': {'axis': 'F', 'class': 'split_dims', 'dims': (-1, 1), 'from': 'source'}}
newbob_learning_rate_decay = 0.9
newbob_multi_num_epochs = 20
newbob_multi_update_interval = 1
num_epochs = 10
optimizer_epsilon = 1e-08
preload_from_files = { 'import': { 'filename': '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/crnn/training/CRNNTrainingJob.BuA0PAYkfiWP/output/models/epoch.295',
              'ignore_missing': True,
              'init_for_train': True}}
save_interval = 1
search_output_layer = 'decision'
target = 'classes'
task = 'train'
tf_log_memory_usage = True
train = { 'audio': { 'features': 'mfcc',
             'norm_mean': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/stats.mean.txt',
             'norm_std_dev': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/stats.std_dev.txt',
             'step_len': 0.01,
             'window_len': 0.025},
  'class': 'LibriSpeechCorpus',
  'epoch_wise_filter': None,
  'partition_epoch': 20,
  'path': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/ogg-zips',
  'prefix': 'train',
  'seq_ordering': 'laplace:281',
  'targets': { 'bpe_file': '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/bpe/train/ReturnnTrainBpeJob.GdFCt6YOja1s/output/bpe.codes',
               'class': 'BytePairEncoding',
               'seq_postfix': [0],
               'unknown_label': None,
               'vocab_file': '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/bpe/train/ReturnnTrainBpeJob.GdFCt6YOja1s/output/bpe.vocab'},
  'use_cache_manager': True,
  'use_ogg': True,
  'use_zip': True}
truncation = -1
update_on_device = True
use_learning_rate_control_always = True
use_tensorflow = True
window = 1
config = {}

locals().update(**config)


import os
import numpy
from subprocess import check_output, CalledProcessError
from Pretrain import WrapEpochValue
from LmDataset import Lexicon


_cf_cache = {}

def cf(filename):
    """Cache manager"""
    if filename in _cf_cache:
        return _cf_cache[filename]
    if debug_mode or check_output(["hostname"]).strip().decode("utf8") in ["cluster-cn-211", "sulfid"]:
        print("use local file: %s" % filename)
        return filename  # for debugging
    try:
        cached_fn = check_output(["cf", filename]).strip().decode("utf8")
    except CalledProcessError:
        print("Cache manager: Error occured, using local file")
        return filename
    assert os.path.exists(cached_fn)
    _cf_cache[filename] = cached_fn
    return cached_fn


def _fix_layer(layer_dict):
  if layer_dict["class"] == "rec":
      unit = layer_dict["unit"]
      if isinstance(unit, dict):
          _fix_net(unit)
          return
  layer_dict["trainable"] = False
  if "dropout" in layer_dict:
      layer_dict["dropout"] = 0


def _fix_net(net_dict):
    for key, value in net_dict.items():
        _fix_layer(value)
        
_fix_net(network)


network["output"]["unit"]["att_lstm"]["trainable"] = True
network["output"]["unit"]["att"]["trainable"] = True

