#!rnn.py

def summary(name, x):
  """
  :param str name:
  :param tf.Tensor x: (batch,time,feature)
  """
  import tensorflow as tf
  # tf.summary.image wants [batch_size, height,  width, channels],
  # we have (batch, time, feature).
  img = tf.expand_dims(x, axis=3)  # (batch,time,feature,1)
  img = tf.transpose(img, [0, 2, 1, 3])  # (batch,feature,time,1)
  tf.summary.image(name, img, max_outputs=10)
  tf.summary.scalar("%s_max_abs" % name, tf.reduce_max(tf.abs(x)))
  mean = tf.reduce_mean(x)
  tf.summary.scalar("%s_mean" % name, mean)
  stddev = tf.sqrt(tf.reduce_mean(tf.square(x - mean)))
  tf.summary.scalar("%s_stddev" % name, stddev)
  tf.summary.histogram("%s_hist" % name, tf.reduce_max(tf.abs(x), axis=2))

def _mask(x, axis, pos, max_amount):
  """
  :param tf.Tensor x: (batch,time,feature)
  :param int axis:
  :param tf.Tensor pos: (batch,)
  :param int max_amount: inclusive
  """
  import tensorflow as tf
  ndim = x.get_shape().ndims
  n_batch = tf.shape(x)[0]
  dim = tf.shape(x)[axis]
  amount = tf.random_uniform(shape=(n_batch,), minval=1, maxval=max_amount + 1, dtype=tf.int32)
  pos2 = tf.minimum(pos + amount, dim)
  idxs = tf.expand_dims(tf.range(0, dim), 0)  # (1,dim)
  pos_bc = tf.expand_dims(pos, 1)  # (batch,1)
  pos2_bc = tf.expand_dims(pos2, 1)  # (batch,1)
  cond = tf.logical_and(tf.greater_equal(idxs, pos_bc), tf.less(idxs, pos2_bc))  # (batch,dim)
  cond = tf.reshape(cond, [tf.shape(x)[i] if i in (0, axis) else 1 for i in range(ndim)])
  from TFUtil import where_bc
  x = where_bc(cond, 0.0, x)
  return x

def random_mask(x, axis, min_num, max_num, max_dims):
  """
  :param tf.Tensor x: (batch,time,feature)
  :param int axis:
  :param int|tf.Tensor min_num:
  :param int|tf.Tensor max_num: inclusive
  :param int max_dims: inclusive
  """
  import tensorflow as tf
  n_batch = tf.shape(x)[0]
  num = tf.random_uniform(shape=(n_batch,), minval=min_num, maxval=max_num + 1, dtype=tf.int32)
  # https://github.com/tensorflow/tensorflow/issues/9260
  # https://timvieira.github.io/blog/post/2014/08/01/gumbel-max-trick-and-weighted-reservoir-sampling/
  z = -tf.log(-tf.log(tf.random_uniform((n_batch, tf.shape(x)[axis]), 0, 1)))
  _, indices = tf.nn.top_k(z, tf.reduce_max(num))
  # indices should be sorted, and of shape (batch,num), entries (int32) in [0,dim)
  # indices = tf.Print(indices, ["indices", indices, tf.shape(indices)])
  _, x = tf.while_loop(
    cond=lambda i, _: tf.less(i, tf.reduce_max(num)),
    body=lambda i, x: (
      i + 1,
      tf.where(
        tf.less(i, num),
        _mask(x, axis=axis, pos=indices[:, i], max_amount=max_dims),
        x)),
    loop_vars=(0, x))
  return x

def transform(data, network):
  x = data.placeholder
  import tensorflow as tf
  x = tf.clip_by_value(x, -3.0, 3.0)

  def get_masked():
    x_masked = x
    x_masked = random_mask(x_masked, axis=1, min_num=1, max_num=tf.maximum(tf.shape(x)[1] // 100, 1), max_dims=20)
    x_masked = random_mask(x_masked, axis=2, min_num=1, max_num=2, max_dims=40 // 5)
    return x_masked

  x = network.cond_on_train(get_masked, lambda: x)
  return x

def custom_construction_algo(idx, net_dict):
  # For debugging, use: python3 ./crnn/Pretrain.py config... Maybe set repetitions=1 below.
  StartNumLayers = 2
  InitialDimFactor = 0.5
  orig_num_lstm_layers = 0
  while "lstm%i_fw" % orig_num_lstm_layers in net_dict:
    orig_num_lstm_layers += 1
  assert orig_num_lstm_layers >= 2
  orig_red_factor = 1
  for i in range(orig_num_lstm_layers - 1):
    orig_red_factor *= net_dict["lstm%i_pool" % i]["pool_size"][0]
  net_dict["#config"] = {}
  if idx < 4:
    net_dict["#config"]["batch_size"] = 20000
  idx = max(idx - 4, 0)  # repeat first
  num_lstm_layers = idx + StartNumLayers  # idx starts at 0. start with N layers
  if num_lstm_layers > orig_num_lstm_layers:
    # Finish. This will also use label-smoothing then.
    return None
  if num_lstm_layers == 2:
    net_dict["lstm0_pool"]["pool_size"] = (orig_red_factor,)
  # Skip to num layers.
  net_dict["encoder"]["from"] = ["lstm%i_fw" % (num_lstm_layers - 1), "lstm%i_bw" % (num_lstm_layers - 1)]
  # Delete non-used lstm layers. This is not explicitly necessary but maybe nicer.
  for i in range(num_lstm_layers, orig_num_lstm_layers):
    del net_dict["lstm%i_fw" % i]
    del net_dict["lstm%i_bw" % i]
    del net_dict["lstm%i_pool" % (i - 1)]
  # Thus we have layers 0 .. (num_lstm_layers - 1).
  layer_idxs = list(range(0, num_lstm_layers))
  layers = ["lstm%i_fw" % i for i in layer_idxs] + ["lstm%i_bw" % i for i in layer_idxs]
  grow_frac = 1.0 - float(orig_num_lstm_layers - num_lstm_layers) / (orig_num_lstm_layers - StartNumLayers)
  dim_frac = InitialDimFactor + (1.0 - InitialDimFactor) * grow_frac
  for layer in layers:
    net_dict[layer]["n_out"] = int(net_dict[layer]["n_out"] * dim_frac)
    if "dropout" in net_dict[layer]:
      net_dict[layer]["dropout"] *= dim_frac
    if "L2" in net_dict[layer]:
      net_dict[layer]['L2'] *= dim_frac
  net_dict["enc_value"]["dims"] = (AttNumHeads, int(EncValuePerHeadDim * dim_frac * 0.5) * 2)
  # Use label smoothing only at the very end.
  if 'loss_opts' in net_dict["output"]["unit"]["output_prob"]:
    net_dict["output"]["unit"]["output_prob"]["loss_opts"]["label_smoothing"] = 0
  return net_dict


AttNumHeads = 1
EncValuePerHeadDim = 2048
accum_grad_multiple_step = 2
adam = True
batch_size = 4200
batching = 'random'
cache_size = '0'
cleanup_old_models = True
debug_mode = False
debug_print_layer_output_template = True
device = 'gpu'
eval_datasets = { 'devtrain': { 'audio': { 'features': 'mfcc',
                           'norm_mean': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/stats.mean.txt',
                           'norm_std_dev': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/stats.std_dev.txt',
                           'step_len': 0.01,
                           'window_len': 0.025},
                'class': 'LibriSpeechCorpus',
                'fixed_random_seed': 1,
                'fixed_random_subset': 3000,
                'path': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/ogg-zips',
                'prefix': 'train',
                'seq_ordering': 'sorted_reverse',
                'targets': { 'bpe_file': '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/bpe/train/ReturnnTrainBpeJob.GdFCt6YOja1s/output/bpe.codes',
                             'class': 'BytePairEncoding',
                             'seq_postfix': [0],
                             'unknown_label': '<unk>',
                             'vocab_file': '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/bpe/train/ReturnnTrainBpeJob.GdFCt6YOja1s/output/bpe.vocab'},
                'use_cache_manager': True,
                'use_ogg': True,
                'use_zip': True}}
extern_data = {'classes': {'dim': 10025, 'shape': (None,), 'sparse': True}, 'data': {'dim': 40, 'shape': (None, 40)}}
forward_override_hdf_output = True
gradient_clip = 0
gradient_noise = 0.0
learning_rate = 0.0008
learning_rate_control = 'newbob_multi_epoch'
learning_rate_control_min_num_epochs_per_new_lr = 3
learning_rate_control_relative_error_relative_lr = True
learning_rates = [ 0.0003,
  0.0003555555555555555,
  0.0004111111111111111,
  0.00046666666666666666,
  0.0005222222222222222,
  0.0005777777777777778,
  0.0006333333333333334,
  0.0006888888888888888,
  0.0007444444444444445,
  0.0008]
load = '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/crnn/training/CRNNTrainingJob.BuA0PAYkfiWP/output/models/epoch.295'
log = ['./crnn.log']
log_batch_size = True
log_verbosity = 5
max_seq_length = 0
max_seqs = 200
min_learning_rate = 1.6e-05
multiprocessing = True
need_data = False
network = { 'conv0': { 'L2': 0.0001,
             'activation': None,
             'class': 'conv',
             'filter_size': (3, 3),
             'from': 'source0',
             'n_out': 32,
             'padding': 'same',
             'with_bias': True},
  'conv0p': {'class': 'pool', 'from': 'conv0', 'mode': 'max', 'padding': 'same', 'pool_size': (1, 2), 'trainable': False},
  'conv1': { 'L2': 0.0001,
             'activation': None,
             'class': 'conv',
             'filter_size': (3, 3),
             'from': 'conv0p',
             'n_out': 32,
             'padding': 'same',
             'with_bias': True},
  'conv1p': {'class': 'pool', 'from': 'conv1', 'mode': 'max', 'padding': 'same', 'pool_size': (1, 2), 'trainable': False},
  'conv_merged': {'axes': 'static', 'class': 'merge_dims', 'from': 'conv1p'},
  'ctc': { 'class': 'softmax',
           'from': 'encoder',
           'loss': 'ctc',
           'loss_opts': {'beam_width': 1, 'ctc_opts': {'ignore_longer_outputs_than_inputs': True}},
           'target': 'classes'},
  'decision': {'class': 'decide', 'from': 'output', 'loss': 'edit_distance', 'target': 'classes'},
  'enc_ctx': {'L2': 0.0001, 'activation': None, 'class': 'linear', 'from': 'encoder', 'n_out': 1024, 'with_bias': True},
  'enc_value': {'axis': 'F', 'class': 'split_dims', 'dims': (1, 2048), 'from': 'encoder'},
  'encoder': {'class': 'copy', 'from': ['lstm5_fw', 'lstm5_bw']},
  'encoder_mean': {'axes': ['t'], 'class': 'reduce', 'from': 'encoder', 'keep_dims': False, 'mode': 'mean'},
  'inv_fertility': {'activation': 'sigmoid', 'class': 'linear', 'from': 'encoder', 'n_out': 1, 'with_bias': False},
  'lstm0_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': 'conv_merged', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm0_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': 'conv_merged', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm0_pool': {'class': 'pool', 'from': ['lstm0_fw', 'lstm0_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (3,), 'trainable': False},
  'lstm1_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': 'lstm0_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm1_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': 'lstm0_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm1_pool': {'class': 'pool', 'from': ['lstm1_fw', 'lstm1_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (2,), 'trainable': False},
  'lstm2_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': 'lstm1_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm2_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': 'lstm1_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm2_pool': {'class': 'pool', 'from': ['lstm2_fw', 'lstm2_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
  'lstm3_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': 'lstm2_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm3_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': 'lstm2_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm3_pool': {'class': 'pool', 'from': ['lstm3_fw', 'lstm3_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
  'lstm4_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': 'lstm3_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm4_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': 'lstm3_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm4_pool': {'class': 'pool', 'from': ['lstm4_fw', 'lstm4_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
  'lstm5_bw': {'L2': 0.0001, 'class': 'rec', 'direction': -1, 'dropout': 0.3, 'from': 'lstm4_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'lstm5_fw': {'L2': 0.0001, 'class': 'rec', 'direction': 1, 'dropout': 0.3, 'from': 'lstm4_pool', 'n_out': 1024, 'unit': 'nativelstm2'},
  'output': { 'class': 'rec',
              'from': [],
              'max_seq_len': "max_len_from('base:encoder')",
              'target': 'classes',
              'unit': { 'accum_att_weights': { 'class': 'eval',
                                               'eval': 'source(0) + source(1) * source(2) * 0.5',
                                               'from': ['prev:accum_att_weights', 'att_weights', 'base:inv_fertility'],
                                               'out_type': {'dim': 1, 'shape': (None, 1)}},
                        'att': {'axes': 'except_batch', 'class': 'merge_dims', 'from': 'att0'},
                        'att0': {'base': 'base:enc_value', 'class': 'generic_attention', 'weights': 'att_weights'},
                        'att_weights': {'class': 'softmax_over_spatial', 'from': 'energy'},
                        'combo_output_prob': { 'class': 'eval',
                                               'eval': 'safe_log(source(0)) + 0.38000000000000006 * safe_log(source(1)) - 0.27999999999999997 * '
                                                       'safe_log(source(2))',
                                               'from': ['output_prob', 'lm_output', 'prior_output_prob']},
                        'end': {'class': 'compare', 'from': 'output', 'kind': 'equal', 'value': 0},
                        'energy': {'activation': None, 'class': 'linear', 'from': 'energy_tanh', 'n_out': 1, 'with_bias': False},
                        'energy_in': {'class': 'combine', 'from': ['base:enc_ctx', 'weight_feedback', 's_transformed'], 'kind': 'add', 'n_out': 1024},
                        'energy_tanh': {'activation': 'tanh', 'class': 'activation', 'from': 'energy_in'},
                        'is_first_frame': {'class': 'compare', 'from': ':i', 'kind': 'equal', 'value': 0},
                        'lm_dec_0': {'class': 'copy', 'from': 'lm_dec_0_ff_out'},
                        'lm_dec_0_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_0_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_0_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_0_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_0_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_0_ff_conv2'},
                        'lm_dec_0_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_0_self_att_out'},
                        'lm_dec_0_ff_out': {'class': 'combine', 'from': ['lm_dec_0_ff_drop', 'lm_dec_0_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_0_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_0_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_0_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_0_self_att_lin'},
                        'lm_dec_0_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_target_embed_lin'},
                        'lm_dec_0_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_0_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_0_self_att_out': { 'class': 'combine',
                                                   'from': ['lm_dec_0_self_att_drop', 'lm_target_embed_lin'],
                                                   'kind': 'add',
                                                   'n_out': 1024},
                        'lm_dec_1': {'class': 'copy', 'from': 'lm_dec_1_ff_out'},
                        'lm_dec_10': {'class': 'copy', 'from': 'lm_dec_10_ff_out'},
                        'lm_dec_10_ff_conv1': { 'activation': 'relu',
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_10_ff_laynorm',
                                                'n_out': 4096,
                                                'with_bias': True},
                        'lm_dec_10_ff_conv2': { 'activation': None,
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_10_ff_conv1',
                                                'n_out': 1024,
                                                'with_bias': True},
                        'lm_dec_10_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_10_ff_conv2'},
                        'lm_dec_10_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_10_self_att_out'},
                        'lm_dec_10_ff_out': { 'class': 'combine',
                                              'from': ['lm_dec_10_ff_drop', 'lm_dec_10_self_att_out'],
                                              'kind': 'add',
                                              'n_out': 1024},
                        'lm_dec_10_self_att_att': { 'attention_left_only': True,
                                                    'class': 'self_attention',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_10_self_att_laynorm',
                                                    'n_out': 1024,
                                                    'num_heads': 8,
                                                    'total_key_dim': 1024},
                        'lm_dec_10_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_10_self_att_lin'},
                        'lm_dec_10_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_9'},
                        'lm_dec_10_self_att_lin': { 'activation': None,
                                                    'class': 'linear',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_10_self_att_att',
                                                    'n_out': 1024,
                                                    'with_bias': False},
                        'lm_dec_10_self_att_out': {'class': 'combine', 'from': ['lm_dec_10_self_att_drop', 'lm_dec_9'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_11': {'class': 'copy', 'from': 'lm_dec_11_ff_out'},
                        'lm_dec_11_ff_conv1': { 'activation': 'relu',
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_11_ff_laynorm',
                                                'n_out': 4096,
                                                'with_bias': True},
                        'lm_dec_11_ff_conv2': { 'activation': None,
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_11_ff_conv1',
                                                'n_out': 1024,
                                                'with_bias': True},
                        'lm_dec_11_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_11_ff_conv2'},
                        'lm_dec_11_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_11_self_att_out'},
                        'lm_dec_11_ff_out': { 'class': 'combine',
                                              'from': ['lm_dec_11_ff_drop', 'lm_dec_11_self_att_out'],
                                              'kind': 'add',
                                              'n_out': 1024},
                        'lm_dec_11_self_att_att': { 'attention_left_only': True,
                                                    'class': 'self_attention',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_11_self_att_laynorm',
                                                    'n_out': 1024,
                                                    'num_heads': 8,
                                                    'total_key_dim': 1024},
                        'lm_dec_11_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_11_self_att_lin'},
                        'lm_dec_11_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_10'},
                        'lm_dec_11_self_att_lin': { 'activation': None,
                                                    'class': 'linear',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_11_self_att_att',
                                                    'n_out': 1024,
                                                    'with_bias': False},
                        'lm_dec_11_self_att_out': { 'class': 'combine',
                                                    'from': ['lm_dec_11_self_att_drop', 'lm_dec_10'],
                                                    'kind': 'add',
                                                    'n_out': 1024},
                        'lm_dec_12': {'class': 'copy', 'from': 'lm_dec_12_ff_out'},
                        'lm_dec_12_ff_conv1': { 'activation': 'relu',
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_12_ff_laynorm',
                                                'n_out': 4096,
                                                'with_bias': True},
                        'lm_dec_12_ff_conv2': { 'activation': None,
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_12_ff_conv1',
                                                'n_out': 1024,
                                                'with_bias': True},
                        'lm_dec_12_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_12_ff_conv2'},
                        'lm_dec_12_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_12_self_att_out'},
                        'lm_dec_12_ff_out': { 'class': 'combine',
                                              'from': ['lm_dec_12_ff_drop', 'lm_dec_12_self_att_out'],
                                              'kind': 'add',
                                              'n_out': 1024},
                        'lm_dec_12_self_att_att': { 'attention_left_only': True,
                                                    'class': 'self_attention',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_12_self_att_laynorm',
                                                    'n_out': 1024,
                                                    'num_heads': 8,
                                                    'total_key_dim': 1024},
                        'lm_dec_12_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_12_self_att_lin'},
                        'lm_dec_12_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_11'},
                        'lm_dec_12_self_att_lin': { 'activation': None,
                                                    'class': 'linear',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_12_self_att_att',
                                                    'n_out': 1024,
                                                    'with_bias': False},
                        'lm_dec_12_self_att_out': { 'class': 'combine',
                                                    'from': ['lm_dec_12_self_att_drop', 'lm_dec_11'],
                                                    'kind': 'add',
                                                    'n_out': 1024},
                        'lm_dec_13': {'class': 'copy', 'from': 'lm_dec_13_ff_out'},
                        'lm_dec_13_ff_conv1': { 'activation': 'relu',
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_13_ff_laynorm',
                                                'n_out': 4096,
                                                'with_bias': True},
                        'lm_dec_13_ff_conv2': { 'activation': None,
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_13_ff_conv1',
                                                'n_out': 1024,
                                                'with_bias': True},
                        'lm_dec_13_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_13_ff_conv2'},
                        'lm_dec_13_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_13_self_att_out'},
                        'lm_dec_13_ff_out': { 'class': 'combine',
                                              'from': ['lm_dec_13_ff_drop', 'lm_dec_13_self_att_out'],
                                              'kind': 'add',
                                              'n_out': 1024},
                        'lm_dec_13_self_att_att': { 'attention_left_only': True,
                                                    'class': 'self_attention',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_13_self_att_laynorm',
                                                    'n_out': 1024,
                                                    'num_heads': 8,
                                                    'total_key_dim': 1024},
                        'lm_dec_13_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_13_self_att_lin'},
                        'lm_dec_13_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_12'},
                        'lm_dec_13_self_att_lin': { 'activation': None,
                                                    'class': 'linear',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_13_self_att_att',
                                                    'n_out': 1024,
                                                    'with_bias': False},
                        'lm_dec_13_self_att_out': { 'class': 'combine',
                                                    'from': ['lm_dec_13_self_att_drop', 'lm_dec_12'],
                                                    'kind': 'add',
                                                    'n_out': 1024},
                        'lm_dec_14': {'class': 'copy', 'from': 'lm_dec_14_ff_out'},
                        'lm_dec_14_ff_conv1': { 'activation': 'relu',
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_14_ff_laynorm',
                                                'n_out': 4096,
                                                'with_bias': True},
                        'lm_dec_14_ff_conv2': { 'activation': None,
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_14_ff_conv1',
                                                'n_out': 1024,
                                                'with_bias': True},
                        'lm_dec_14_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_14_ff_conv2'},
                        'lm_dec_14_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_14_self_att_out'},
                        'lm_dec_14_ff_out': { 'class': 'combine',
                                              'from': ['lm_dec_14_ff_drop', 'lm_dec_14_self_att_out'],
                                              'kind': 'add',
                                              'n_out': 1024},
                        'lm_dec_14_self_att_att': { 'attention_left_only': True,
                                                    'class': 'self_attention',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_14_self_att_laynorm',
                                                    'n_out': 1024,
                                                    'num_heads': 8,
                                                    'total_key_dim': 1024},
                        'lm_dec_14_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_14_self_att_lin'},
                        'lm_dec_14_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_13'},
                        'lm_dec_14_self_att_lin': { 'activation': None,
                                                    'class': 'linear',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_14_self_att_att',
                                                    'n_out': 1024,
                                                    'with_bias': False},
                        'lm_dec_14_self_att_out': { 'class': 'combine',
                                                    'from': ['lm_dec_14_self_att_drop', 'lm_dec_13'],
                                                    'kind': 'add',
                                                    'n_out': 1024},
                        'lm_dec_15': {'class': 'copy', 'from': 'lm_dec_15_ff_out'},
                        'lm_dec_15_ff_conv1': { 'activation': 'relu',
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_15_ff_laynorm',
                                                'n_out': 4096,
                                                'with_bias': True},
                        'lm_dec_15_ff_conv2': { 'activation': None,
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_15_ff_conv1',
                                                'n_out': 1024,
                                                'with_bias': True},
                        'lm_dec_15_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_15_ff_conv2'},
                        'lm_dec_15_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_15_self_att_out'},
                        'lm_dec_15_ff_out': { 'class': 'combine',
                                              'from': ['lm_dec_15_ff_drop', 'lm_dec_15_self_att_out'],
                                              'kind': 'add',
                                              'n_out': 1024},
                        'lm_dec_15_self_att_att': { 'attention_left_only': True,
                                                    'class': 'self_attention',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_15_self_att_laynorm',
                                                    'n_out': 1024,
                                                    'num_heads': 8,
                                                    'total_key_dim': 1024},
                        'lm_dec_15_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_15_self_att_lin'},
                        'lm_dec_15_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_14'},
                        'lm_dec_15_self_att_lin': { 'activation': None,
                                                    'class': 'linear',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_15_self_att_att',
                                                    'n_out': 1024,
                                                    'with_bias': False},
                        'lm_dec_15_self_att_out': { 'class': 'combine',
                                                    'from': ['lm_dec_15_self_att_drop', 'lm_dec_14'],
                                                    'kind': 'add',
                                                    'n_out': 1024},
                        'lm_dec_16': {'class': 'copy', 'from': 'lm_dec_16_ff_out'},
                        'lm_dec_16_ff_conv1': { 'activation': 'relu',
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_16_ff_laynorm',
                                                'n_out': 4096,
                                                'with_bias': True},
                        'lm_dec_16_ff_conv2': { 'activation': None,
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_16_ff_conv1',
                                                'n_out': 1024,
                                                'with_bias': True},
                        'lm_dec_16_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_16_ff_conv2'},
                        'lm_dec_16_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_16_self_att_out'},
                        'lm_dec_16_ff_out': { 'class': 'combine',
                                              'from': ['lm_dec_16_ff_drop', 'lm_dec_16_self_att_out'],
                                              'kind': 'add',
                                              'n_out': 1024},
                        'lm_dec_16_self_att_att': { 'attention_left_only': True,
                                                    'class': 'self_attention',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_16_self_att_laynorm',
                                                    'n_out': 1024,
                                                    'num_heads': 8,
                                                    'total_key_dim': 1024},
                        'lm_dec_16_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_16_self_att_lin'},
                        'lm_dec_16_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_15'},
                        'lm_dec_16_self_att_lin': { 'activation': None,
                                                    'class': 'linear',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_16_self_att_att',
                                                    'n_out': 1024,
                                                    'with_bias': False},
                        'lm_dec_16_self_att_out': { 'class': 'combine',
                                                    'from': ['lm_dec_16_self_att_drop', 'lm_dec_15'],
                                                    'kind': 'add',
                                                    'n_out': 1024},
                        'lm_dec_17': {'class': 'copy', 'from': 'lm_dec_17_ff_out'},
                        'lm_dec_17_ff_conv1': { 'activation': 'relu',
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_17_ff_laynorm',
                                                'n_out': 4096,
                                                'with_bias': True},
                        'lm_dec_17_ff_conv2': { 'activation': None,
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_17_ff_conv1',
                                                'n_out': 1024,
                                                'with_bias': True},
                        'lm_dec_17_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_17_ff_conv2'},
                        'lm_dec_17_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_17_self_att_out'},
                        'lm_dec_17_ff_out': { 'class': 'combine',
                                              'from': ['lm_dec_17_ff_drop', 'lm_dec_17_self_att_out'],
                                              'kind': 'add',
                                              'n_out': 1024},
                        'lm_dec_17_self_att_att': { 'attention_left_only': True,
                                                    'class': 'self_attention',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_17_self_att_laynorm',
                                                    'n_out': 1024,
                                                    'num_heads': 8,
                                                    'total_key_dim': 1024},
                        'lm_dec_17_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_17_self_att_lin'},
                        'lm_dec_17_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_16'},
                        'lm_dec_17_self_att_lin': { 'activation': None,
                                                    'class': 'linear',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_17_self_att_att',
                                                    'n_out': 1024,
                                                    'with_bias': False},
                        'lm_dec_17_self_att_out': { 'class': 'combine',
                                                    'from': ['lm_dec_17_self_att_drop', 'lm_dec_16'],
                                                    'kind': 'add',
                                                    'n_out': 1024},
                        'lm_dec_18': {'class': 'copy', 'from': 'lm_dec_18_ff_out'},
                        'lm_dec_18_ff_conv1': { 'activation': 'relu',
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_18_ff_laynorm',
                                                'n_out': 4096,
                                                'with_bias': True},
                        'lm_dec_18_ff_conv2': { 'activation': None,
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_18_ff_conv1',
                                                'n_out': 1024,
                                                'with_bias': True},
                        'lm_dec_18_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_18_ff_conv2'},
                        'lm_dec_18_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_18_self_att_out'},
                        'lm_dec_18_ff_out': { 'class': 'combine',
                                              'from': ['lm_dec_18_ff_drop', 'lm_dec_18_self_att_out'],
                                              'kind': 'add',
                                              'n_out': 1024},
                        'lm_dec_18_self_att_att': { 'attention_left_only': True,
                                                    'class': 'self_attention',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_18_self_att_laynorm',
                                                    'n_out': 1024,
                                                    'num_heads': 8,
                                                    'total_key_dim': 1024},
                        'lm_dec_18_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_18_self_att_lin'},
                        'lm_dec_18_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_17'},
                        'lm_dec_18_self_att_lin': { 'activation': None,
                                                    'class': 'linear',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_18_self_att_att',
                                                    'n_out': 1024,
                                                    'with_bias': False},
                        'lm_dec_18_self_att_out': { 'class': 'combine',
                                                    'from': ['lm_dec_18_self_att_drop', 'lm_dec_17'],
                                                    'kind': 'add',
                                                    'n_out': 1024},
                        'lm_dec_19': {'class': 'copy', 'from': 'lm_dec_19_ff_out'},
                        'lm_dec_19_ff_conv1': { 'activation': 'relu',
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_19_ff_laynorm',
                                                'n_out': 4096,
                                                'with_bias': True},
                        'lm_dec_19_ff_conv2': { 'activation': None,
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_19_ff_conv1',
                                                'n_out': 1024,
                                                'with_bias': True},
                        'lm_dec_19_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_19_ff_conv2'},
                        'lm_dec_19_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_19_self_att_out'},
                        'lm_dec_19_ff_out': { 'class': 'combine',
                                              'from': ['lm_dec_19_ff_drop', 'lm_dec_19_self_att_out'],
                                              'kind': 'add',
                                              'n_out': 1024},
                        'lm_dec_19_self_att_att': { 'attention_left_only': True,
                                                    'class': 'self_attention',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_19_self_att_laynorm',
                                                    'n_out': 1024,
                                                    'num_heads': 8,
                                                    'total_key_dim': 1024},
                        'lm_dec_19_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_19_self_att_lin'},
                        'lm_dec_19_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_18'},
                        'lm_dec_19_self_att_lin': { 'activation': None,
                                                    'class': 'linear',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_19_self_att_att',
                                                    'n_out': 1024,
                                                    'with_bias': False},
                        'lm_dec_19_self_att_out': { 'class': 'combine',
                                                    'from': ['lm_dec_19_self_att_drop', 'lm_dec_18'],
                                                    'kind': 'add',
                                                    'n_out': 1024},
                        'lm_dec_1_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_1_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_1_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_1_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_1_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_1_ff_conv2'},
                        'lm_dec_1_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_1_self_att_out'},
                        'lm_dec_1_ff_out': {'class': 'combine', 'from': ['lm_dec_1_ff_drop', 'lm_dec_1_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_1_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_1_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_1_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_1_self_att_lin'},
                        'lm_dec_1_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_0'},
                        'lm_dec_1_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_1_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_1_self_att_out': {'class': 'combine', 'from': ['lm_dec_1_self_att_drop', 'lm_dec_0'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_2': {'class': 'copy', 'from': 'lm_dec_2_ff_out'},
                        'lm_dec_20': {'class': 'copy', 'from': 'lm_dec_20_ff_out'},
                        'lm_dec_20_ff_conv1': { 'activation': 'relu',
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_20_ff_laynorm',
                                                'n_out': 4096,
                                                'with_bias': True},
                        'lm_dec_20_ff_conv2': { 'activation': None,
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_20_ff_conv1',
                                                'n_out': 1024,
                                                'with_bias': True},
                        'lm_dec_20_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_20_ff_conv2'},
                        'lm_dec_20_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_20_self_att_out'},
                        'lm_dec_20_ff_out': { 'class': 'combine',
                                              'from': ['lm_dec_20_ff_drop', 'lm_dec_20_self_att_out'],
                                              'kind': 'add',
                                              'n_out': 1024},
                        'lm_dec_20_self_att_att': { 'attention_left_only': True,
                                                    'class': 'self_attention',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_20_self_att_laynorm',
                                                    'n_out': 1024,
                                                    'num_heads': 8,
                                                    'total_key_dim': 1024},
                        'lm_dec_20_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_20_self_att_lin'},
                        'lm_dec_20_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_19'},
                        'lm_dec_20_self_att_lin': { 'activation': None,
                                                    'class': 'linear',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_20_self_att_att',
                                                    'n_out': 1024,
                                                    'with_bias': False},
                        'lm_dec_20_self_att_out': { 'class': 'combine',
                                                    'from': ['lm_dec_20_self_att_drop', 'lm_dec_19'],
                                                    'kind': 'add',
                                                    'n_out': 1024},
                        'lm_dec_21': {'class': 'copy', 'from': 'lm_dec_21_ff_out'},
                        'lm_dec_21_ff_conv1': { 'activation': 'relu',
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_21_ff_laynorm',
                                                'n_out': 4096,
                                                'with_bias': True},
                        'lm_dec_21_ff_conv2': { 'activation': None,
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_21_ff_conv1',
                                                'n_out': 1024,
                                                'with_bias': True},
                        'lm_dec_21_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_21_ff_conv2'},
                        'lm_dec_21_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_21_self_att_out'},
                        'lm_dec_21_ff_out': { 'class': 'combine',
                                              'from': ['lm_dec_21_ff_drop', 'lm_dec_21_self_att_out'],
                                              'kind': 'add',
                                              'n_out': 1024},
                        'lm_dec_21_self_att_att': { 'attention_left_only': True,
                                                    'class': 'self_attention',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_21_self_att_laynorm',
                                                    'n_out': 1024,
                                                    'num_heads': 8,
                                                    'total_key_dim': 1024},
                        'lm_dec_21_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_21_self_att_lin'},
                        'lm_dec_21_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_20'},
                        'lm_dec_21_self_att_lin': { 'activation': None,
                                                    'class': 'linear',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_21_self_att_att',
                                                    'n_out': 1024,
                                                    'with_bias': False},
                        'lm_dec_21_self_att_out': { 'class': 'combine',
                                                    'from': ['lm_dec_21_self_att_drop', 'lm_dec_20'],
                                                    'kind': 'add',
                                                    'n_out': 1024},
                        'lm_dec_22': {'class': 'copy', 'from': 'lm_dec_22_ff_out'},
                        'lm_dec_22_ff_conv1': { 'activation': 'relu',
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_22_ff_laynorm',
                                                'n_out': 4096,
                                                'with_bias': True},
                        'lm_dec_22_ff_conv2': { 'activation': None,
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_22_ff_conv1',
                                                'n_out': 1024,
                                                'with_bias': True},
                        'lm_dec_22_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_22_ff_conv2'},
                        'lm_dec_22_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_22_self_att_out'},
                        'lm_dec_22_ff_out': { 'class': 'combine',
                                              'from': ['lm_dec_22_ff_drop', 'lm_dec_22_self_att_out'],
                                              'kind': 'add',
                                              'n_out': 1024},
                        'lm_dec_22_self_att_att': { 'attention_left_only': True,
                                                    'class': 'self_attention',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_22_self_att_laynorm',
                                                    'n_out': 1024,
                                                    'num_heads': 8,
                                                    'total_key_dim': 1024},
                        'lm_dec_22_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_22_self_att_lin'},
                        'lm_dec_22_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_21'},
                        'lm_dec_22_self_att_lin': { 'activation': None,
                                                    'class': 'linear',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_22_self_att_att',
                                                    'n_out': 1024,
                                                    'with_bias': False},
                        'lm_dec_22_self_att_out': { 'class': 'combine',
                                                    'from': ['lm_dec_22_self_att_drop', 'lm_dec_21'],
                                                    'kind': 'add',
                                                    'n_out': 1024},
                        'lm_dec_23': {'class': 'copy', 'from': 'lm_dec_23_ff_out'},
                        'lm_dec_23_ff_conv1': { 'activation': 'relu',
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_23_ff_laynorm',
                                                'n_out': 4096,
                                                'with_bias': True},
                        'lm_dec_23_ff_conv2': { 'activation': None,
                                                'class': 'linear',
                                                'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                        'scale=1.0)',
                                                'from': 'lm_dec_23_ff_conv1',
                                                'n_out': 1024,
                                                'with_bias': True},
                        'lm_dec_23_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_23_ff_conv2'},
                        'lm_dec_23_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_23_self_att_out'},
                        'lm_dec_23_ff_out': { 'class': 'combine',
                                              'from': ['lm_dec_23_ff_drop', 'lm_dec_23_self_att_out'],
                                              'kind': 'add',
                                              'n_out': 1024},
                        'lm_dec_23_self_att_att': { 'attention_left_only': True,
                                                    'class': 'self_attention',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_23_self_att_laynorm',
                                                    'n_out': 1024,
                                                    'num_heads': 8,
                                                    'total_key_dim': 1024},
                        'lm_dec_23_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_23_self_att_lin'},
                        'lm_dec_23_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_22'},
                        'lm_dec_23_self_att_lin': { 'activation': None,
                                                    'class': 'linear',
                                                    'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                            'scale=1.0)',
                                                    'from': 'lm_dec_23_self_att_att',
                                                    'n_out': 1024,
                                                    'with_bias': False},
                        'lm_dec_23_self_att_out': { 'class': 'combine',
                                                    'from': ['lm_dec_23_self_att_drop', 'lm_dec_22'],
                                                    'kind': 'add',
                                                    'n_out': 1024},
                        'lm_dec_2_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_2_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_2_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_2_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_2_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_2_ff_conv2'},
                        'lm_dec_2_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_2_self_att_out'},
                        'lm_dec_2_ff_out': {'class': 'combine', 'from': ['lm_dec_2_ff_drop', 'lm_dec_2_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_2_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_2_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_2_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_2_self_att_lin'},
                        'lm_dec_2_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_1'},
                        'lm_dec_2_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_2_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_2_self_att_out': {'class': 'combine', 'from': ['lm_dec_2_self_att_drop', 'lm_dec_1'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_3': {'class': 'copy', 'from': 'lm_dec_3_ff_out'},
                        'lm_dec_3_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_3_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_3_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_3_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_3_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_3_ff_conv2'},
                        'lm_dec_3_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_3_self_att_out'},
                        'lm_dec_3_ff_out': {'class': 'combine', 'from': ['lm_dec_3_ff_drop', 'lm_dec_3_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_3_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_3_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_3_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_3_self_att_lin'},
                        'lm_dec_3_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_2'},
                        'lm_dec_3_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_3_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_3_self_att_out': {'class': 'combine', 'from': ['lm_dec_3_self_att_drop', 'lm_dec_2'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_4': {'class': 'copy', 'from': 'lm_dec_4_ff_out'},
                        'lm_dec_4_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_4_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_4_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_4_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_4_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_4_ff_conv2'},
                        'lm_dec_4_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_4_self_att_out'},
                        'lm_dec_4_ff_out': {'class': 'combine', 'from': ['lm_dec_4_ff_drop', 'lm_dec_4_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_4_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_4_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_4_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_4_self_att_lin'},
                        'lm_dec_4_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_3'},
                        'lm_dec_4_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_4_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_4_self_att_out': {'class': 'combine', 'from': ['lm_dec_4_self_att_drop', 'lm_dec_3'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_5': {'class': 'copy', 'from': 'lm_dec_5_ff_out'},
                        'lm_dec_5_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_5_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_5_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_5_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_5_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_5_ff_conv2'},
                        'lm_dec_5_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_5_self_att_out'},
                        'lm_dec_5_ff_out': {'class': 'combine', 'from': ['lm_dec_5_ff_drop', 'lm_dec_5_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_5_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_5_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_5_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_5_self_att_lin'},
                        'lm_dec_5_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_4'},
                        'lm_dec_5_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_5_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_5_self_att_out': {'class': 'combine', 'from': ['lm_dec_5_self_att_drop', 'lm_dec_4'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_6': {'class': 'copy', 'from': 'lm_dec_6_ff_out'},
                        'lm_dec_6_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_6_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_6_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_6_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_6_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_6_ff_conv2'},
                        'lm_dec_6_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_6_self_att_out'},
                        'lm_dec_6_ff_out': {'class': 'combine', 'from': ['lm_dec_6_ff_drop', 'lm_dec_6_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_6_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_6_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_6_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_6_self_att_lin'},
                        'lm_dec_6_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_5'},
                        'lm_dec_6_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_6_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_6_self_att_out': {'class': 'combine', 'from': ['lm_dec_6_self_att_drop', 'lm_dec_5'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_7': {'class': 'copy', 'from': 'lm_dec_7_ff_out'},
                        'lm_dec_7_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_7_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_7_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_7_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_7_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_7_ff_conv2'},
                        'lm_dec_7_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_7_self_att_out'},
                        'lm_dec_7_ff_out': {'class': 'combine', 'from': ['lm_dec_7_ff_drop', 'lm_dec_7_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_7_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_7_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_7_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_7_self_att_lin'},
                        'lm_dec_7_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_6'},
                        'lm_dec_7_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_7_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_7_self_att_out': {'class': 'combine', 'from': ['lm_dec_7_self_att_drop', 'lm_dec_6'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_8': {'class': 'copy', 'from': 'lm_dec_8_ff_out'},
                        'lm_dec_8_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_8_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_8_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_8_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_8_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_8_ff_conv2'},
                        'lm_dec_8_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_8_self_att_out'},
                        'lm_dec_8_ff_out': {'class': 'combine', 'from': ['lm_dec_8_ff_drop', 'lm_dec_8_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_8_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_8_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_8_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_8_self_att_lin'},
                        'lm_dec_8_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_7'},
                        'lm_dec_8_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_8_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_8_self_att_out': {'class': 'combine', 'from': ['lm_dec_8_self_att_drop', 'lm_dec_7'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_9': {'class': 'copy', 'from': 'lm_dec_9_ff_out'},
                        'lm_dec_9_ff_conv1': { 'activation': 'relu',
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_9_ff_laynorm',
                                               'n_out': 4096,
                                               'with_bias': True},
                        'lm_dec_9_ff_conv2': { 'activation': None,
                                               'class': 'linear',
                                               'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                       'scale=1.0)',
                                               'from': 'lm_dec_9_ff_conv1',
                                               'n_out': 1024,
                                               'with_bias': True},
                        'lm_dec_9_ff_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_9_ff_conv2'},
                        'lm_dec_9_ff_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_9_self_att_out'},
                        'lm_dec_9_ff_out': {'class': 'combine', 'from': ['lm_dec_9_ff_drop', 'lm_dec_9_self_att_out'], 'kind': 'add', 'n_out': 1024},
                        'lm_dec_9_self_att_att': { 'attention_left_only': True,
                                                   'class': 'self_attention',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_9_self_att_laynorm',
                                                   'n_out': 1024,
                                                   'num_heads': 8,
                                                   'total_key_dim': 1024},
                        'lm_dec_9_self_att_drop': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_dec_9_self_att_lin'},
                        'lm_dec_9_self_att_laynorm': {'class': 'layer_norm', 'from': 'lm_dec_8'},
                        'lm_dec_9_self_att_lin': { 'activation': None,
                                                   'class': 'linear',
                                                   'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                           'scale=1.0)',
                                                   'from': 'lm_dec_9_self_att_att',
                                                   'n_out': 1024,
                                                   'with_bias': False},
                        'lm_dec_9_self_att_out': {'class': 'combine', 'from': ['lm_dec_9_self_att_drop', 'lm_dec_8'], 'kind': 'add', 'n_out': 1024},
                        'lm_decoder': {'class': 'layer_norm', 'from': 'lm_dec_23'},
                        'lm_output': { 'class': 'softmax',
                                       'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', scale=1.0)",
                                       'from': 'lm_decoder',
                                       'loss': None,
                                       'target': 'classes',
                                       'with_bias': True},
                        'lm_target_embed': {'class': 'dropout', 'dropout': 0.0, 'from': 'lm_target_embed_with_pos'},
                        'lm_target_embed_lin': { 'activation': None,
                                                 'class': 'linear',
                                                 'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                         'scale=1.0)',
                                                 'from': 'lm_target_embed',
                                                 'n_out': 1024,
                                                 'with_bias': False},
                        'lm_target_embed_raw': { 'activation': None,
                                                 'class': 'linear',
                                                 'forward_weights_init': "variance_scaling_initializer(mode='fan_in', distribution='uniform', "
                                                                         'scale=1.0)',
                                                 'from': 'prev:output',
                                                 'n_out': 128,
                                                 'param_device': 'CPU',
                                                 'with_bias': False},
                        'lm_target_embed_with_pos': {'add_to_input': True, 'class': 'positional_encoding', 'from': 'lm_target_embed_raw'},
                        'output': { 'beam_size': 32,
                                    'class': 'choice',
                                    'from': 'combo_output_prob',
                                    'initial_output': 0,
                                    'input_type': 'log_prob',
                                    'target': 'classes'},
                        'output_prob': { 'L2': 0.0001,
                                         'class': 'softmax',
                                         'dropout': 0.3,
                                         'from': 'readout',
                                         'loss': 'ce',
                                         'loss_opts': {'label_smoothing': 0.1},
                                         'target': 'classes'},
                        'prev_att': {'class': 'switch', 'condition': 'is_first_frame', 'false_from': 'base:encoder_mean', 'true_from': 'zero_att'},
                        'prior_output_prob': { 'L2': 0.0001,
                                               'class': 'softmax',
                                               'dropout': 0.3,
                                               'from': ['prior_readout'],
                                               'loss': 'ce',
                                               'loss_opts': {'label_smoothing': 0.1},
                                               'target': 'classes'},
                        'prior_readout': {'class': 'reduce_out', 'from': ['prior_readout_in'], 'mode': 'max', 'num_pieces': 2},
                        'prior_readout_in': { 'activation': None,
                                              'class': 'linear',
                                              'from': ['prior_s', 'prev:target_embed', 'base:encoder_mean'],
                                              'n_out': 1000,
                                              'with_bias': True},
                        'prior_s': {'L2': 0.0001, 'class': 'rnn_cell', 'from': ['prev:target_embed', 'prev_att'], 'n_out': 1000, 'unit': 'LSTMBlock'},
                        'readout': {'class': 'reduce_out', 'from': 'readout_in', 'mode': 'max', 'num_pieces': 2},
                        'readout_in': { 'activation': None,
                                        'class': 'linear',
                                        'from': ['s', 'prev:target_embed', 'att'],
                                        'n_out': 1000,
                                        'with_bias': True},
                        's': {'L2': 0.0001, 'class': 'rnn_cell', 'from': ['prev:target_embed', 'prev:att'], 'n_out': 1000, 'unit': 'LSTMBlock'},
                        's_transformed': {'activation': None, 'class': 'linear', 'from': 's', 'n_out': 1024, 'with_bias': False},
                        'target_embed': { 'activation': None,
                                          'class': 'linear',
                                          'from': 'output',
                                          'initial_output': 0,
                                          'n_out': 621,
                                          'with_bias': False},
                        'weight_feedback': { 'activation': None,
                                             'class': 'linear',
                                             'from': 'prev:accum_att_weights',
                                             'n_out': 1024,
                                             'with_bias': False},
                        'zero_att': {'class': 'eval', 'eval': 'tf.zeros_like(source(0))', 'from': 'att'}}},
  'source': { 'class': 'eval',
              'eval': "self.network.get_config().typed_value('transform')(source(0, as_data=True), network=self.network)",
              'from': 'data'},
  'source0': {'axis': 'F', 'class': 'split_dims', 'dims': (-1, 1), 'from': 'source'}}
newbob_learning_rate_decay = 0.9
newbob_multi_num_epochs = 20
newbob_multi_update_interval = 1
num_epochs = 300
optimizer_epsilon = 1e-08
preload_from_files = { 'lm_model': { 'filename': '/work/asr3/irie/experiments/lm/librispeech/2018-03-05--lmbpe-zeyer/data-train/transfo_24_d00.4096_1024.sgd.lr1.8_heads/bk-net-model/network.023',
                'prefix': 'lm_'},
  'prior_lm': { 'filename': '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/crnn/training/CRNNTrainingJob.BuA0PAYkfiWP/output/models/epoch.295',
                'prefix': 'prior_'}}
pretrain = {'construction_algo': custom_construction_algo, 'copy_param_mode': 'subset', 'repetitions': 5}
search_data = { 'audio': { 'features': 'mfcc',
             'norm_mean': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/stats.mean.txt',
             'norm_std_dev': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/stats.std_dev.txt',
             'step_len': 0.01,
             'window_len': 0.025},
  'class': 'LibriSpeechCorpus',
  'fixed_random_seed': 1,
  'path': '/u/zeineldeen/setups/librispeech/2020-08-31--att-phon/dataset/ogg-zips',
  'prefix': 'dev-other',
  'seq_ordering': 'sorted_reverse',
  'targets': { 'bpe_file': '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/bpe/train/ReturnnTrainBpeJob.GdFCt6YOja1s/output/bpe.codes',
               'class': 'BytePairEncoding',
               'seq_postfix': [0],
               'unknown_label': '<unk>',
               'vocab_file': '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/bpe/train/ReturnnTrainBpeJob.GdFCt6YOja1s/output/bpe.vocab'},
  'use_cache_manager': True,
  'use_ogg': True,
  'use_zip': True}
search_do_eval = 0
search_output_file = '/u/zeineldeen/setups/librispeech/2021-01-14--att-bpe-sis/work/crnn/search/CRNNSearchJob.dp8BJrTPVQ43/output/search_out'
search_output_file_format = 'py'
search_output_layer = 'decision'
target = 'classes'
task = 'search'
tf_log_memory_usage = True
truncation = -1
update_on_device = True
use_learning_rate_control_always = True
use_tensorflow = True
window = 1
config = {}

locals().update(**config)


import os
import numpy
from subprocess import check_output, CalledProcessError
from Pretrain import WrapEpochValue
from LmDataset import Lexicon


_cf_cache = {}

def cf(filename):
    """Cache manager"""
    if filename in _cf_cache:
        return _cf_cache[filename]
    if debug_mode or check_output(["hostname"]).strip().decode("utf8") in ["cluster-cn-211", "sulfid"]:
        print("use local file: %s" % filename)
        return filename  # for debugging
    try:
        cached_fn = check_output(["cf", filename]).strip().decode("utf8")
    except CalledProcessError:
        print("Cache manager: Error occured, using local file")
        return filename
    assert os.path.exists(cached_fn)
    _cf_cache[filename] = cached_fn
    return cached_fn
import sys
sys.setrecursionlimit(4000)
