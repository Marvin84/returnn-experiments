#!rnn.py



accum_grad_multiple_step = 2
batch_size = 16000
cleanup_old_models = True
debug_print_layer_output_template = True
dev = { 'class': 'MetaDataset',
  'data_map': {'classes': ('audio', 'classes'), 'data': ('audio', 'data'), 'speaker_label': ('speaker', 'data')},
  'datasets': { 'audio': { 'audio': { 'feature_options': {'fmax': 7600, 'fmin': 60},
                                      'features': 'db_mel_filterbank',
                                      'norm_mean': -72.84156436920165,
                                      'norm_std_dev': 28.825260819294442,
                                      'num_feature_filters': 80,
                                      'peak_normalization': False,
                                      'preemphasis': 0.97,
                                      'step_len': 0.0125,
                                      'window_len': 0.05},
                           'class': 'OggZipDataset',
                           'partition_epoch': 2,
                           'path': '</path/to/librispeech100h.ogg.zip>',
                           'segment_file': '</path/to/librspeech100h-speaker-dev.segments>',
                           'seq_ordering': 'laplace:.1000',
                           'targets': { 'class': 'Vocabulary',
                                        'unknown_label': None,
                                        'vocab_file': '</path/to/cmu_vocab.pkl>'},
                           'use_cache_manager': True},
                'speaker': { 'class': 'HDFDataset',
                             'files': [ '</path/to/speaker_labels.hdf']}},
  'seq_order_control_dataset': 'audio'}
device = 'gpu'
extern_data = { 'classes': {'dim': 77, 'shape': (None,), 'sparse': True},
  'data': {'dim': 80, 'shape': (None, 80)},
  'speaker_label': {'dim': 251, 'shape': (None,), 'sparse': True}}
gradient_clip = 1
gradient_noise = 0
learning_rate = 0.001
learning_rate_control = 'newbob_multi_epoch'
learning_rate_control_min_num_epochs_per_new_lr = 5
learning_rate_control_relative_error_relative_lr = True
learning_rate_file = 'learning_rates'
learning_rates = [0.001]
log = ['./returnn.log']
log_batch_size = True
log_verbosity = 5
max_seq_length = {'data': 1290}
max_seqs = 200
model = '</path/to/models/epoch>'
multiprocessing = True
network = { 'dec_output': {'axes': ['T', 'static:0'], 'class': 'merge_dims', 'from': ['dec_output_split'], 'n_out': 80},
  'dec_output_split': {'axis': 'F', 'class': 'split_dims', 'dims': (3, -1), 'from': ['decoder']},
  'decoder': { 'cheating': False,
               'class': 'rec',
               'from': [],
               'max_seq_len': 1000,
               'target': 'windowed_data_target',
               'unit': { 'accum_att_weights': { 'class': 'combine',
                                                'from': ['prev:accum_att_weights', 'att_weights'],
                                                'is_output_layer': True,
                                                'kind': 'add'},
                         'att0': {'base': 'base:encoder', 'class': 'generic_attention', 'weights': 'att_weights'},
                         'att_energy': {'activation': None, 'class': 'linear', 'from': ['att_energy_tanh'], 'n_out': 1, 'with_bias': False},
                         'att_energy_in': { 'class': 'combine',
                                            'from': ['base:enc_ctx', 's_transformed', 'location_feedback_transformed'],
                                            'kind': 'add',
                                            'n_out': 128},
                         'att_energy_tanh': {'activation': 'tanh', 'class': 'activation', 'from': ['att_energy_in']},
                         'att_weights': {'class': 'softmax_over_spatial', 'from': ['att_energy']},
                         'choice': { 'beam_size': 1,
                                     'class': 'choice',
                                     'from': ['output'],
                                     'input_type': 'regression',
                                     'target': 'windowed_data_target'},
                         'convolved_att': { 'L2': 1e-07,
                                            'activation': None,
                                            'class': 'conv',
                                            'filter_size': (31,),
                                            'from': ['feedback_pad_right'],
                                            'n_out': 32,
                                            'padding': 'valid'},
                         'decoder_1': { 'class': 'rnn_cell',
                                        'from': ['pre_net_layer_2_out', 'prev:att0'],
                                        'n_out': 768,
                                        'unit': 'zoneoutlstm',
                                        'unit_opts': {'zoneout_factor_cell': 0.1, 'zoneout_factor_output': 0.1}},
                         'decoder_2': { 'class': 'rnn_cell',
                                        'from': ['decoder_1'],
                                        'n_out': 768,
                                        'unit': 'zoneoutlstm',
                                        'unit_opts': {'zoneout_factor_cell': 0.1, 'zoneout_factor_output': 0.1}},
                         'end': {'class': 'compare', 'from': ['stop_token_sigmoid'], 'kind': 'greater', 'value': 0.5},
                         'entropy': { 'class': 'eval',
                                      'eval': '-tf.reduce_sum(source(0)*safe_log(source(0)), axis=-1, keepdims=True)',
                                      'from': ['att_weights'],
                                      'loss': 'as_is',
                                      'loss_scale': 0.0001},
                         'feedback_pad_left': { 'axes': 's:0',
                                                'class': 'pad',
                                                'from': ['prev:accum_att_weights'],
                                                'mode': 'constant',
                                                'padding': ((15, 0),),
                                                'value': 1},
                         'feedback_pad_right': { 'axes': 's:0',
                                                 'class': 'pad',
                                                 'from': ['feedback_pad_left'],
                                                 'mode': 'constant',
                                                 'padding': ((0, 15),),
                                                 'value': 0},
                         'location_feedback_transformed': { 'L2': 1e-07,
                                                            'activation': None,
                                                            'class': 'linear',
                                                            'dropout': 0.1,
                                                            'from': ['convolved_att'],
                                                            'n_out': 128,
                                                            'with_bias': False},
                         'output': { 'activation': None,
                                     'class': 'linear',
                                     'from': ['decoder_2', 'att0'],
                                     'loss': 'mean_l1',
                                     'loss_scale': 1.0,
                                     'n_out': 240,
                                     'target': 'windowed_data_target'},
                         'pre_net_layer_1': {'L2': 1e-07, 'activation': 'relu', 'class': 'linear', 'from': ['pre_slice'], 'n_out': 128},
                         'pre_net_layer_2': { 'L2': 1e-07,
                                              'activation': 'relu',
                                              'class': 'linear',
                                              'dropout': 0.5,
                                              'dropout_noise_shape': {'*': None},
                                              'dropout_on_forward': True,
                                              'from': ['pre_net_layer_1'],
                                              'n_out': 64},
                         'pre_net_layer_2_out': { 'class': 'dropout',
                                                  'dropout': 0.5,
                                                  'dropout_noise_shape': {'*': None},
                                                  'dropout_on_forward': True,
                                                  'from': ['pre_net_layer_2']},
                         'pre_slice': {'axis': 'F', 'class': 'slice', 'from': ['prev:choice'], 'slice_start': 160},
                         's_transformed': { 'L2': 1e-07,
                                            'activation': None,
                                            'class': 'linear',
                                            'dropout': 0.5,
                                            'from': ['decoder_2'],
                                            'n_out': 128,
                                            'with_bias': False},
                         'stop_token': { 'activation': None,
                                         'class': 'linear',
                                         'from': ['decoder_2', 'att0'],
                                         'loss': 'bin_ce',
                                         'loss_scale': 1.0,
                                         'n_out': 1,
                                         'target': 'stop_token_target'},
                         'stop_token_sigmoid': {'activation': 'sigmoid', 'class': 'activation', 'from': ['stop_token']}}},
  'embed_batchnorm_cv_0': { 'class': 'batch_norm',
                            'delay_sample_update': True,
                            'epsilon': 0.001,
                            'from': ['embed_conv0'],
                            'momentum': 0.1,
                            'update_sample_only_in_training': True},
  'embed_batchnorm_cv_1': { 'class': 'batch_norm',
                            'delay_sample_update': True,
                            'epsilon': 0.001,
                            'from': ['embed_conv1'],
                            'momentum': 0.1,
                            'update_sample_only_in_training': True},
  'embed_batchnorm_cv_2': { 'class': 'batch_norm',
                            'delay_sample_update': True,
                            'epsilon': 0.001,
                            'from': ['embed_conv2'],
                            'momentum': 0.1,
                            'update_sample_only_in_training': True},
  'embed_conv0': {'L2': 1e-07, 'activation': 'relu', 'class': 'conv', 'filter_size': (5,), 'from': ['embedding'], 'n_out': 256, 'padding': 'same'},
  'embed_conv0_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': {'*': None}, 'from': ['embed_batchnorm_cv_0']},
  'embed_conv1': { 'L2': 1e-07,
                   'activation': 'relu',
                   'class': 'conv',
                   'filter_size': (5,),
                   'from': ['embed_conv0_out'],
                   'n_out': 256,
                   'padding': 'same'},
  'embed_conv1_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': {'*': None}, 'from': ['embed_batchnorm_cv_1']},
  'embed_conv2': { 'L2': 1e-07,
                   'activation': 'relu',
                   'class': 'conv',
                   'filter_size': (5,),
                   'from': ['embed_conv1_out'],
                   'n_out': 256,
                   'padding': 'same'},
  'embed_conv2_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': {'*': None}, 'from': ['embed_batchnorm_cv_2']},
  'embedding': {'activation': None, 'class': 'linear', 'from': ['data:classes'], 'n_out': 256},
  'enc_ctx': { 'L2': 1e-07,
               'activation': None,
               'class': 'linear',
               'dropout': 0.5,
               'from': ['encoder', 'encoder_position'],
               'n_out': 128,
               'with_bias': True},
  'encoder': {'class': 'copy', 'dropout': 0.1, 'dropout_noise_shape': {'*': None}, 'from': ['lstm0_fw', 'lstm0_bw', 'speaker_embedding']},
  'encoder_position': {'class': 'positional_encoding', 'from': ['lstm0_fw'], 'n_out': 64, 'out_type': {'dim': 64, 'shape': (None, 64)}},
  'lstm0_bw': {'class': 'rec', 'direction': -1, 'from': ['embed_conv2_out'], 'n_out': 256, 'unit': 'nativelstm2'},
  'lstm0_fw': {'class': 'rec', 'direction': 1, 'from': ['embed_conv2_out'], 'n_out': 256, 'unit': 'nativelstm2'},
  'mse_output': {'class': 'copy', 'from': ['output'], 'loss': 'mse', 'loss_scale': 0.0, 'n_out': 80, 'target': 'padded_data_target'},
  'output': { 'class': 'combine',
              'from': ['dec_output', 'post_conv_tf'],
              'kind': 'add',
              'loss': 'mean_l1',
              'loss_scale': 0.25,
              'n_out': 80,
              'target': 'padded_data_target'},
  'padded_data_target': { 'axes': ['T', 'static:0'],
                          'class': 'merge_dims',
                          'from': ['windowed_data'],
                          'n_out': 80,
                          'register_as_extern_data': 'padded_data_target'},
  'post_batchnorm_cv_0': {'class': 'batch_norm', 'from': ['post_conv0']},
  'post_batchnorm_cv_1': {'class': 'batch_norm', 'from': ['post_conv1']},
  'post_batchnorm_cv_2': {'class': 'batch_norm', 'from': ['post_conv2']},
  'post_batchnorm_cv_3': {'class': 'batch_norm', 'from': ['post_conv3']},
  'post_batchnorm_cv_4': {'class': 'batch_norm', 'from': ['post_conv4']},
  'post_conv0': {'L2': 1e-07, 'activation': 'relu', 'class': 'conv', 'filter_size': (5,), 'from': ['dec_output'], 'n_out': 256, 'padding': 'same'},
  'post_conv0_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': {'*': None}, 'from': ['post_batchnorm_cv_0']},
  'post_conv1': { 'L2': 1e-07,
                  'activation': 'relu',
                  'class': 'conv',
                  'filter_size': (5,),
                  'from': ['post_conv0_out'],
                  'n_out': 256,
                  'padding': 'same'},
  'post_conv1_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': {'*': None}, 'from': ['post_batchnorm_cv_1']},
  'post_conv2': { 'L2': 1e-07,
                  'activation': 'relu',
                  'class': 'conv',
                  'filter_size': (5,),
                  'from': ['post_conv1_out'],
                  'n_out': 256,
                  'padding': 'same'},
  'post_conv2_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': {'*': None}, 'from': ['post_batchnorm_cv_2']},
  'post_conv3': { 'L2': 1e-07,
                  'activation': 'relu',
                  'class': 'conv',
                  'filter_size': (5,),
                  'from': ['post_conv2_out'],
                  'n_out': 256,
                  'padding': 'same'},
  'post_conv3_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': {'*': None}, 'from': ['post_batchnorm_cv_3']},
  'post_conv4': { 'L2': 1e-07,
                  'activation': 'relu',
                  'class': 'conv',
                  'filter_size': (5,),
                  'from': ['post_conv3_out'],
                  'n_out': 256,
                  'padding': 'same'},
  'post_conv4_out': {'class': 'dropout', 'dropout': 0.5, 'dropout_noise_shape': {'*': None}, 'from': ['post_batchnorm_cv_4']},
  'post_conv_tf': {'activation': None, 'class': 'conv', 'filter_size': (5,), 'from': ['post_conv4_out'], 'n_out': 80, 'padding': 'same'},
  'speaker_embedding': {'activation': None, 'class': 'linear', 'from': ['speaker_label_notime'], 'n_out': 256},
  'speaker_label_notime': {'axis': 'T', 'class': 'squeeze', 'from': ['data:speaker_label']},
  'stop_token_target': { 'class': 'eval',
                         'eval': "self.network.get_config().typed_value('_stop_token_target')(source(0, as_data=True))",
                         'from': ['windowed_data_target'],
                         'out_type': {'dim': 1, 'shape': (None, 1)},
                         'register_as_extern_data': 'stop_token_target'},
  'windowed_data': {'class': 'window', 'from': ['data'], 'stride': 3, 'window_right': 2, 'window_size': 3},
  'windowed_data_target': { 'axes': 'static',
                            'class': 'merge_dims',
                            'from': ['windowed_data'],
                            'n_out': 240,
                            'register_as_extern_data': 'windowed_data_target'}}
newbob_learning_rate_decay = 0.9
newbob_multi_num_epochs = 3
newbob_multi_update_interval = 1
newbob_relative_error_threshold = 0
num_epochs = 200
optimizer = {'class': 'adam', 'epsilon': 1e-08}
save_interval = 1
stop_on_nonfinite_train_score = False
target = 'classes'
task = 'train'
tf_log_memory_usage = True
train = { 'class': 'MetaDataset',
  'data_map': {'classes': ('audio', 'classes'), 'data': ('audio', 'data'), 'speaker_label': ('speaker', 'data')},
  'datasets': { 'audio': { 'audio': { 'feature_options': {'fmax': 7600, 'fmin': 60},
                                      'features': 'db_mel_filterbank',
                                      'norm_mean': -72.84156436920165,
                                      'norm_std_dev': 28.825260819294442,
                                      'num_feature_filters': 80,
                                      'peak_normalization': False,
                                      'preemphasis': 0.97,
                                      'step_len': 0.0125,
                                      'window_len': 0.05},
                           'class': 'OggZipDataset',
                           'partition_epoch': 2,
                           'path': '</path/to/librispeech100h.ogg.zip>',
                           'segment_file': '</path/to/librspeech100h-speaker-train.segments>',
                           'seq_ordering': 'laplace:.1000',
                           'targets': { 'class': 'Vocabulary',
                                        'unknown_label': None,
                                        'vocab_file': '</path/to/cmu_vocab.pkl>'},
                           'use_cache_manager': True},
                'speaker': { 'class': 'HDFDataset',
                             'files': [ '</path/to/speaker_labels.hdf']}},
  'seq_order_control_dataset': 'audio'}
use_learning_rate_control_always = True
use_tensorflow = True
config = {}

locals().update(**config)


def custom_construction_algo(idx, net_dict):
  if idx == 5:
    return None
  
  postnet_loss_scale = max(min((idx/5*1.00), 1.00), 0.01)
  stop_token_loss_scale = min(idx/5, 1.0) 
  net_dict['output']['loss_scale'] = postnet_loss_scale
  net_dict['decoder']['unit']['stop_token']['loss_scale'] = stop_token_loss_scale 
    
  return net_dict

pretrain = {"repetitions": 5, "construction_algo": custom_construction_algo}
    
def _stop_token_target(data):
  import tensorflow as tf
  time_axis = data.get_dynamic_axes()[0]
  stop_position = tf.expand_dims(data.get_dynamic_size(time_axis), axis=1) - 6
  ramp = tf.expand_dims(tf.range(tf.shape(data.placeholder)[1]), axis=0)
  full_ramp = tf.tile(ramp, [tf.shape(data.placeholder)[0], 1])
  adapted_ramp = tf.minimum(tf.maximum(full_ramp - stop_position, 0), 5)
  return tf.cast(tf.expand_dims(adapted_ramp, 2), dtype="float32") / 5

