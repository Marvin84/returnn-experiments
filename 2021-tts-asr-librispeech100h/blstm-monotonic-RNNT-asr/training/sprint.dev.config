[*]
configuration.channel    = output-channel
dot.channel              = nil
encoding                 = UTF-8
error.channel            = output-channel, stderr
log.channel              = output-channel
progress.channel         = output-channel
python-home              = <<<python-env-home>>>
python-program-name      = <<<python-bin>>>
real-time-factor.channel = output-channel
statistics.channel       = output-channel
system-info.channel      = output-channel
time.channel             = output-channel
version.channel          = output-channel
warning.channel          = output-channel, stderr

[*.output-channel]
append     = no
compressed = no
file       = $(LOGFILE)
unbuffered = yes

[neural-network-trainer]
action                                             = supervised-training
aligning-feature-extractor.feature-extraction.file = dev.feature.flow
buffer-size                                        = 204800
buffer-type                                        = utterance
class-labels.save-to-file                          = class.labels
estimator                                          = steepest-descent
feature-extraction.file                            = dummy.flow
regression-window-size                             = 5
shuffle                                            = no
silence-weight                                     = 1.0
single-precision                                   = yes
trainer-output-dimension                           = 139
training-criterion                                 = cross-entropy
weighted-alignment                                 = no
window-size                                        = 1
window-size-derivatives                            = 0

[neural-network-trainer.*]
peak-position           = 1.0
peaky-alignment         = yes
reduce-alignment-factor = 2

[neural-network-trainer.corpus]
audio-dir                      = /
capitalize-transcriptions      = no
file                           = <<<merged-dev-cv-and-train.corpus.gz>>>
progress-indication            = global
segments.file                  = <<<dev-cv.segments>>>
warn-about-unexpected-elements = yes

[neural-network-trainer.model-combination.acoustic-model]
state-tying.type = monophone-eow

[neural-network-trainer.model-combination.acoustic-model.allophones]
add-all          = yes
add-from-file    = <<<allophones>>>
add-from-lexicon = no

[neural-network-trainer.model-combination.acoustic-model.hmm]
across-word-model   = yes
early-recombination = no
state-repetitions   = 1
states-per-phone    = 1

[neural-network-trainer.model-combination.acoustic-model.phonology]
future-length  = 0
history-length = 0

[neural-network-trainer.model-combination.acoustic-model.tdp]
entry-m1.loop = infinity
entry-m2.loop = infinity
scale         = 1.0

[neural-network-trainer.model-combination.acoustic-model.tdp.*]
exit    = 0
forward = 0
loop    = 0
skip    = 0

[neural-network-trainer.model-combination.acoustic-model.tdp.silence]
exit    = 0
forward = 0
loop    = 0
skip    = 0

[neural-network-trainer.model-combination.lexicon]
file                    = <<<lexicon.xml>>>
normalize-pronunciation = no
