[*]
configuration.channel    = output-channel
dot.channel              = nil
encoding                 = UTF-8
error.channel            = output-channel, stderr
log.channel              = output-channel
progress.channel         = output-channel
real-time-factor.channel = output-channel
statistics.channel       = output-channel
system-info.channel      = output-channel
time.channel             = output-channel
version.channel          = output-channel
warning.channel          = output-channel, stderr

[*.output-channel]
append     = no
compressed = no
file       = $(LOGFILE)
unbuffered = yes

[flf-lattice-tool.corpus]
audio-dir                      = /
capitalize-transcriptions      = no
file                           = <<<LibriSpeech/corpora/dev-other.corpus>>>
progress-indication            = global
segments.file                  = <<<dev-other-segments.$(TASK)>>>
warn-about-unexpected-elements = yes

[flf-lattice-tool.global-cache]
file      = <<<global.cache>>>
read-only = yes

[flf-lattice-tool.lexicon]
file                    = <<<eow.lexicon.xml>>>
normalize-pronunciation = no

[flf-lattice-tool.network]
initial-nodes = segment

[flf-lattice-tool.network.archive-writer]
format = flf
info   = yes
links  = sink:1
path   = lattice.cache.$(TASK)
type   = archive-writer

[flf-lattice-tool.network.evaluator]
best-in-lattice = yes
links           = sink:0
single-best     = yes
type            = evaluator
word-errors     = yes

[flf-lattice-tool.network.evaluator.edit-distance]
allow-broken-words = no
format             = bliss

[flf-lattice-tool.network.recognizer]
add-confidence-score          = no
apply-non-word-closure-filter = no
apply-posterior-pruning       = no
feature-extraction.file       = feature.flow
links                         = evaluator archive-writer
pronunciation-scale           = 1.0
search-type                   = label-sync-search
type                          = recognizer
use-mixture                   = no

[flf-lattice-tool.network.recognizer.acoustic-model]
state-tying.type = monophone-eow

[flf-lattice-tool.network.recognizer.acoustic-model.allophones]
add-all          = yes
add-from-file    = <<<allophones>>>
add-from-lexicon = no

[flf-lattice-tool.network.recognizer.acoustic-model.hmm]
across-word-model   = yes
early-recombination = no
state-repetitions   = 1
states-per-phone    = 1

[flf-lattice-tool.network.recognizer.acoustic-model.phonology]
future-length  = 0
history-length = 0

[flf-lattice-tool.network.recognizer.acoustic-model.tdp]
entry-m1.loop = infinity
entry-m2.loop = infinity
scale         = 1.0

[flf-lattice-tool.network.recognizer.acoustic-model.tdp.*]
exit    = 0
forward = 0
loop    = 0
skip    = 0

[flf-lattice-tool.network.recognizer.acoustic-model.tdp.silence]
exit    = 0
forward = 0
loop    = 0
skip    = 0

[flf-lattice-tool.network.recognizer.label-scorer]
blank-label-index       = 0
label-file              = <<<monophone-eow/vocab>>>
label-scorer-type       = tf-rnn-transducer
max-batch-size          = 256
reduction-factors       = 2
scale                   = 1.0
start-label-index       = 140
transform-output-negate = yes
use-start-label         = yes

[flf-lattice-tool.network.recognizer.label-scorer.feature-input-map.info-0]
param-name             = feature
seq-length-tensor-name = extern_data/placeholders/data/data_dim0_size
tensor-name            = extern_data/placeholders/data/data

[flf-lattice-tool.network.recognizer.label-scorer.loader]
meta-graph-file    = <<<tf-graph.meta>>>
required-libraries = <<<libs/nativelstm2/tf1.12/NativeLstm2.so>>>
saved-model-file   = <<<models/epoch.220>>>
type               = meta

[flf-lattice-tool.network.recognizer.lm]
allow-reduced-history   = yes
max-batch-size          = 64
min-batch-size          = 4
opt-batch-size          = 64
scale                   = 0.9
transform-output-negate = yes
type                    = tfrnn
vocab-file              = <<<lstmlm_vocabulary>>>
vocab-unknown-word      = <UNK>

[flf-lattice-tool.network.recognizer.lm.input-map.info-0]
param-name             = word
seq-length-tensor-name = extern_data/placeholders/delayed/delayed_dim0_size
tensor-name            = extern_data/placeholders/delayed/delayed

[flf-lattice-tool.network.recognizer.lm.loader]
meta-graph-file    = /u/rossenbach/experiments/asru_ls100_full_context_transducer/work/crnn/compile/CompileTFGraphJob.0dxq1DSvOxuN/output/graph.meta
required-libraries = /u/zhou/libs/nativelstm2/tf1.12/NativeLstm2.so
saved-model-file   = /u/zhou/asr-exps/librispeech/dependencies/kazuki_lstmlm_27062019/network.040
type               = meta

[flf-lattice-tool.network.recognizer.lm.output-map.info-0]
param-name  = softmax
tensor-name = output/output_batch_major

[flf-lattice-tool.network.recognizer.recognizer]
allow-blank-label            = yes
allow-label-recombination    = yes
allow-word-end-recombination = yes
create-lattice               = yes
full-sum-decoding            = yes
label-pruning                = 13.5
label-pruning-limit          = 7000
lm-lookahead                 = yes
optimize-lattice             = no
recombination-lm.type        = simple-history
separate-lookahead-lm        = yes
separate-recombination-lm    = yes
word-end-pruning             = 0.5
word-end-pruning-limit       = 20000

[flf-lattice-tool.network.recognizer.recognizer.label-tree]
label-unit   = phoneme
skip-silence = yes

[flf-lattice-tool.network.recognizer.recognizer.lm-lookahead]
cache-size-high = 3000
cache-size-low  = 2000
history-limit   = 1
scale           = 0.45

[flf-lattice-tool.network.recognizer.recognizer.lookahead-lm]
file  = <<<LibriSpeech/lm/4-gram.arpa.gz>>>
image = <<<lm-1.image>>>
scale = 1.0
type  = ARPA

[flf-lattice-tool.network.segment]
links = 1->recognizer:1 0->archive-writer:1 0->evaluator:1
type  = speech-segment

[flf-lattice-tool.network.sink]
error-on-empty-lattice = no
type                   = sink
warn-on-empty-lattice  = yes
