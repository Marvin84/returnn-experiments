#!rnn.py

import os

# EXTERNAL SISYPHUS PARAMETERS
ext_model = config.value("ext_model", None)
ext_learning_rate_file = config.value("ext_learning_rate_file", None)

# training
ext_data_path = config.value("ext_data_path", None) # ogg-zip data path for the synthetic data 
ext_use_pretrained = config.bool("ext_use_pretrained", True) # start training from a predefined checkpoint as defined below
ext_use_baseline_data = config.bool("ext_use_baseline_data", True) # use the LibriSpeech-100h data, if false train on the synthetic data alone

ext_data_sample_factor = config.int("ext_data_sample_factor", 1) # oversampling of the baseline data (1, 2 or 3)

ext_partition_epoch = config.int("ext_partition_epoch", 3) # 3 for baseline, 6 with 1:3 synthetic data, 7 for 2:3 and 9 for 3:3
ext_num_epochs = config.int("ext_num_epochs", 250)

# decoding
ext_decoding = config.bool("ext_decoding", False) # enable decoding
ext_eval_zip = config.value("ext_eval_zip", None) # path to the ogg.zip of the dev/test set
ext_load_epoch = config.int("ext_load_epoch", 0) # which epoch to load

ext_use_lm_with_scale =config.float("ext_use_lm_with_scale", 0.0) # LM combination scale, 0 disables the LM
ext_beam_size = config.int("ext_beam_size", 12)

# Import pretrained model (fixed epoch 80 for this case)
if ext_use_pretrained and not ext_decoding:
    model_check = ext_model + ".080.index"
    if not os.path.exists(model_check):
        import shutil
        base_pretrain = "<<</path/to/baseline/training/output/models/>>>"
        shutil.copyfile(base_pretrain + "epoch.080.index", ext_model + ".080.index")
        shutil.copyfile(base_pretrain + "epoch.080.meta", ext_model + ".080.meta")
        shutil.copyfile(base_pretrain + "epoch.080.data-00000-of-00001", ext_model + ".080.data-00000-of-00001")


def summary(name, x):
  """
  :param str name:
  :param tf.Tensor x: (batch,time,feature)
  """
  from returnn.tf.compat import v1 as tf
  # tf.summary.image wants [batch_size, height,  width, channels],
  # we have (batch, time, feature).
  img = tf.expand_dims(x, axis=3)  # (batch,time,feature,1)
  img = tf.transpose(img, [0, 2, 1, 3])  # (batch,feature,time,1)
  tf.summary.image(name, img, max_outputs=10)
  tf.summary.scalar("%s_max_abs" % name, tf.reduce_max(tf.abs(x)))
  mean = tf.reduce_mean(x)
  tf.summary.scalar("%s_mean" % name, mean)
  stddev = tf.sqrt(tf.reduce_mean(tf.square(x - mean)))
  tf.summary.scalar("%s_stddev" % name, stddev)
  tf.summary.histogram("%s_hist" % name, tf.reduce_max(tf.abs(x), axis=2))

def _mask(x, batch_axis, axis, pos, max_amount):
  """
  :param tf.Tensor x: (batch,time,feature)
  :param int batch_axis:
  :param int axis:
  :param tf.Tensor pos: (batch,)
  :param int|tf.Tensor max_amount: inclusive
  """
  from returnn.tf.compat import v1 as tf
  ndim = x.get_shape().ndims
  n_batch = tf.shape(x)[batch_axis]
  dim = tf.shape(x)[axis]
  amount = tf.random_uniform(shape=(n_batch,), minval=1, maxval=max_amount + 1, dtype=tf.int32)
  pos2 = tf.minimum(pos + amount, dim)
  idxs = tf.expand_dims(tf.range(0, dim), 0)  # (1,dim)
  pos_bc = tf.expand_dims(pos, 1)  # (batch,1)
  pos2_bc = tf.expand_dims(pos2, 1)  # (batch,1)
  cond = tf.logical_and(tf.greater_equal(idxs, pos_bc), tf.less(idxs, pos2_bc))  # (batch,dim)
  if batch_axis > axis:
      cond = tf.transpose(cond)  # (dim,batch)
  cond = tf.reshape(cond, [tf.shape(x)[i] if i in (batch_axis, axis) else 1 for i in range(ndim)])
  from TFUtil import where_bc
  x = where_bc(cond, 0.0, x)
  return x

def random_mask(x, batch_axis, axis, min_num, max_num, max_dims):
  """
  :param tf.Tensor x: (batch,time,feature)
  :param int batch_axis:
  :param int axis:
  :param int|tf.Tensor min_num:
  :param int|tf.Tensor max_num: inclusive
  :param int|tf.Tensor max_dims: inclusive
  """
  from returnn.tf.compat import v1 as tf
  n_batch = tf.shape(x)[batch_axis]
  if isinstance(min_num, int) and isinstance(max_num, int) and min_num == max_num:
      num = min_num
  else:
      num = tf.random_uniform(shape=(n_batch,), minval=min_num, maxval=max_num + 1, dtype=tf.int32)
  # https://github.com/tensorflow/tensorflow/issues/9260
  # https://timvieira.github.io/blog/post/2014/08/01/gumbel-max-trick-and-weighted-reservoir-sampling/
  z = -tf.log(-tf.log(tf.random_uniform((n_batch, tf.shape(x)[axis]), 0, 1)))
  _, indices = tf.nn.top_k(z, num if isinstance(num, int) else tf.reduce_max(num))
  # indices should be sorted, and of shape (batch,num), entries (int32) in [0,dim)
  # indices = tf.Print(indices, ["indices", indices, tf.shape(indices)])
  if isinstance(num, int):
      for i in range(num):
          x = _mask(x, batch_axis=batch_axis, axis=axis, pos=indices[:, i], max_amount=max_dims)
  else:
      _, x = tf.while_loop(
          cond=lambda i, _: tf.less(i, tf.reduce_max(num)),
          body=lambda i, x: (
              i + 1,
              tf.where(
                  tf.less(i, num),
                  _mask(x, batch_axis=batch_axis, axis=axis, pos=indices[:, i], max_amount=max_dims),
                  x)),
          loop_vars=(0, x))
  return x

def transform(data, network, time_factor=1):
  x = data.placeholder
  from returnn.tf.compat import v1 as tf
  # summary("features", x)
  step = network.global_train_step
  step1 = tf.where(tf.greater_equal(step, 1000), 1, 0)
  step2 = tf.where(tf.greater_equal(step, 2000), 1, 0)
  def get_masked():
      x_masked = x
      x_masked = random_mask(
        x_masked, batch_axis=data.batch_dim_axis, axis=data.time_dim_axis,
        min_num=step1 + step2, max_num=tf.maximum(tf.shape(x)[data.time_dim_axis] // 100, 2) * (1 + step1 + step2 * 2),
        max_dims=20 // time_factor)
      x_masked = random_mask(
        x_masked, batch_axis=data.batch_dim_axis, axis=data.feature_dim_axis,
        min_num=step1 + step2, max_num=2 + step1 + step2 * 2,
        max_dims=data.dim // 5)
      #summary("features_mask", x_masked)
      return x_masked
  x = network.cond_on_train(get_masked, lambda: x)
  return x

def custom_construction_algo(idx, net_dict):
  # For debugging, use: python3 ./crnn/Pretrain.py config... Maybe set repetitions=1 below.
  StartNumLayers = 2
  InitialDimFactor = 0.5
  orig_num_lstm_layers = 0
  while "lstm%i_fw" % orig_num_lstm_layers in net_dict:
    orig_num_lstm_layers += 1
  assert orig_num_lstm_layers >= 2
  orig_red_factor = 1
  for i in range(orig_num_lstm_layers - 1):
    orig_red_factor *= net_dict["lstm%i_pool" % i]["pool_size"][0]
  net_dict["#config"] = {}
  if idx < 4:
    net_dict["#config"]["batch_size"] = 15000
  idx = max(idx - 4, 0)  # repeat first
  num_lstm_layers = idx + StartNumLayers  # idx starts at 0. start with N layers
  if num_lstm_layers > orig_num_lstm_layers:
    # Finish. This will also use label-smoothing then.
    return None
  if num_lstm_layers == 2:
    net_dict["lstm0_pool"]["pool_size"] = (orig_red_factor,)
  # Skip to num layers.
  net_dict["encoder"]["from"] = ["lstm%i_fw" % (num_lstm_layers - 1), "lstm%i_bw" % (num_lstm_layers - 1)]
  # Delete non-used lstm layers. This is not explicitly necessary but maybe nicer.
  for i in range(num_lstm_layers, orig_num_lstm_layers):
    del net_dict["lstm%i_fw" % i]
    del net_dict["lstm%i_bw" % i]
    del net_dict["lstm%i_pool" % (i - 1)]
  # Thus we have layers 0 .. (num_lstm_layers - 1).
  layer_idxs = list(range(0, num_lstm_layers))
  layers = ["lstm%i_fw" % i for i in layer_idxs] + ["lstm%i_bw" % i for i in layer_idxs]
  grow_frac = 1.0 - float(orig_num_lstm_layers - num_lstm_layers) / (orig_num_lstm_layers - StartNumLayers)
  dim_frac = InitialDimFactor + (1.0 - InitialDimFactor) * grow_frac
  for layer in layers:
    net_dict[layer]["n_out"] = int(net_dict[layer]["n_out"] * dim_frac)
    if "dropout" in net_dict[layer]:
      net_dict[layer]["dropout"] *= dim_frac
    if "L2" in net_dict[layer]:
      net_dict[layer]['L2'] *= dim_frac
  net_dict["enc_value"]["dims"] = (AttNumHeads, int(EncValuePerHeadDim * dim_frac * 0.5) * 2)
  # Use label smoothing only at the very end.
  net_dict["output"]["unit"]["output_prob"]["loss_opts"]["label_smoothing"] = 0
  return net_dict


AttNumHeads = 1
EncValuePerHeadDim = 2048
accum_grad_multiple_step = 2
adam = True
batch_size = 10000
batching = 'random'
cache_size = '0'
cleanup_old_models = True
debug_mode = False
debug_print_layer_output_template = True
dev = { 'audio': { 'features': 'mfcc',
             'norm_mean': '<<</path/to/librispeech-100h/stats.mean.txt>>>',
             'norm_std_dev': '<<</path/to/librispeech-100h/stats.std_dev.txt>>>',
             'step_len': 0.01,
             'window_len': 0.025},
  'class': 'OggZipDataset',
  'fixed_random_seed': 1,
  'partition_epoch': 1,
  'path': [ '<<</path/to/dev_clean.ogg.zip>>>',
            '<<</path/to/dev_other.ogg.zip>>>'],
  'segment_file': '<<</path/to/dev_train.segments>>>',
  'seq_ordering': 'sorted_reverse',
  'targets': { 'bpe_file': '<<</path/to/librispeech-100h/bpe.codes>>>',
               'class': 'BytePairEncoding',
               'seq_postfix': [0],
               'unknown_label': None,
               'vocab_file': '<<</path/to/librispeech-100h/bpe.vocab>>'},
  'use_cache_manager': True}
device = 'gpu'
eval_datasets = { 'devtrain': { 'audio': { 'features': 'mfcc',
                           'norm_mean': '<<</path/to/librispeech-100h/stats.mean.txt>>>',
                           'norm_std_dev': '<<</path/to/librispeech-100h/stats.std_dev.txt>>>',
                           'step_len': 0.01,
                           'window_len': 0.025},
                'class': 'OggZipDataset',
                'fixed_random_seed': 1,
                'fixed_random_subset': 3000,
                'partition_epoch': 1,
                'path': '</path/to/librispeech-100h.ogg.zip>',
                'seq_ordering': 'sorted_reverse',
                'targets': { 'bpe_file': '<<</path/to/librispeech-100h/bpe.codes>>>',
                             'class': 'BytePairEncoding',
                             'seq_postfix': [0],
                             'unknown_label': None,
                             'vocab_file': '<<</path/to/bpe.vocab>>>'},
                'use_cache_manager': True}}
extern_data = {'classes': {'dim': 2051, 'shape': (None,), 'sparse': True}, 'data': {'dim': 40, 'shape': (None, 40)}}
gradient_clip = 0
gradient_noise = 0.0
learning_rate = 0.0008
learning_rate_control = 'newbob_multi_epoch'
learning_rate_control_min_num_epochs_per_new_lr = 3
learning_rate_control_relative_error_relative_lr = True
learning_rate_file = ext_learning_rate_file
learning_rates = [ 0.0003,
  0.0003,
  0.0003,
  0.0003,
  0.0003,
  0.0003,
  0.0003,
  0.0003,
  0.0003,
  0.0003,
  0.0003,
  0.0003555555555555555,
  0.0004111111111111111,
  0.00046666666666666666,
  0.0005222222222222222,
  0.0005777777777777778,
  0.0006333333333333334,
  0.0006888888888888888,
  0.0007444444444444445,
  0.0008]
log = ['./crnn.log']
log_batch_size = True
log_verbosity = 5
max_seq_len = {'classes': 75}
max_seqs = 200
min_learning_rate = 1.6e-05
model = ext_model
multiprocessing = True
network = { 'conv0': { 'L2': 0.001,
             'activation': None,
             'class': 'conv',
             'filter_size': (3, 3),
             'from': 'source0',
             'n_out': 32,
             'padding': 'same',
             'with_bias': True},
  'conv0p': {'class': 'pool', 'from': 'conv0', 'mode': 'max', 'padding': 'same', 'pool_size': (1, 2), 'trainable': False},
  'conv1': { 'L2': 0.001,
             'activation': None,
             'class': 'conv',
             'filter_size': (3, 3),
             'from': 'conv0p',
             'n_out': 32,
             'padding': 'same',
             'with_bias': True},
  'conv1p': {'class': 'pool', 'from': 'conv1', 'mode': 'max', 'padding': 'same', 'pool_size': (1, 2), 'trainable': False},
  'conv_merged': {'axes': 'static', 'class': 'merge_dims', 'from': 'conv1p'},
  'ctc': { 'class': 'softmax',
           'from': 'encoder',
           'loss': 'ctc',
           'loss_opts': {'beam_width': 1, 'ctc_opts': {'ignore_longer_outputs_than_inputs': True}},
           'target': 'classes'},
  'decision': {'class': 'decide', 'from': 'output', 'loss': 'edit_distance', 'target': 'classes'},
  'enc_ctx': {'L2': 0.001, 'activation': None, 'class': 'linear', 'from': 'encoder', 'n_out': 1024, 'with_bias': True},
  'enc_value': {'axis': 'F', 'class': 'split_dims', 'dims': (1, 2048), 'from': 'encoder'},
  'encoder': {'class': 'copy', 'from': ['lstm5_fw', 'lstm5_bw']},
  'inv_fertility': {'activation': 'sigmoid', 'class': 'linear', 'from': 'encoder', 'n_out': 1, 'with_bias': False},
  'lstm0_bw': { 'L2': 0.001,
                'class': 'rec',
                'direction': -1,
                'dropout': 0.3,
                'from': 'conv_merged',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.3}},
  'lstm0_fw': { 'L2': 0.001,
                'class': 'rec',
                'direction': 1,
                'dropout': 0.3,
                'from': 'conv_merged',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.3}},
  'lstm0_pool': {'class': 'pool', 'from': ['lstm0_fw', 'lstm0_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (3,), 'trainable': False},
  'lstm1_bw': { 'L2': 0.001,
                'class': 'rec',
                'direction': -1,
                'dropout': 0.3,
                'from': 'lstm0_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.3}},
  'lstm1_fw': { 'L2': 0.001,
                'class': 'rec',
                'direction': 1,
                'dropout': 0.3,
                'from': 'lstm0_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.3}},
  'lstm1_pool': {'class': 'pool', 'from': ['lstm1_fw', 'lstm1_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (2,), 'trainable': False},
  'lstm2_bw': { 'L2': 0.001,
                'class': 'rec',
                'direction': -1,
                'dropout': 0.3,
                'from': 'lstm1_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.3}},
  'lstm2_fw': { 'L2': 0.001,
                'class': 'rec',
                'direction': 1,
                'dropout': 0.3,
                'from': 'lstm1_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.3}},
  'lstm2_pool': {'class': 'pool', 'from': ['lstm2_fw', 'lstm2_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
  'lstm3_bw': { 'L2': 0.001,
                'class': 'rec',
                'direction': -1,
                'dropout': 0.3,
                'from': 'lstm2_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.3}},
  'lstm3_fw': { 'L2': 0.001,
                'class': 'rec',
                'direction': 1,
                'dropout': 0.3,
                'from': 'lstm2_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.3}},
  'lstm3_pool': {'class': 'pool', 'from': ['lstm3_fw', 'lstm3_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
  'lstm4_bw': { 'L2': 0.001,
                'class': 'rec',
                'direction': -1,
                'dropout': 0.3,
                'from': 'lstm3_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.3}},
  'lstm4_fw': { 'L2': 0.001,
                'class': 'rec',
                'direction': 1,
                'dropout': 0.3,
                'from': 'lstm3_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.3}},
  'lstm4_pool': {'class': 'pool', 'from': ['lstm4_fw', 'lstm4_bw'], 'mode': 'max', 'padding': 'same', 'pool_size': (1,), 'trainable': False},
  'lstm5_bw': { 'L2': 0.001,
                'class': 'rec',
                'direction': -1,
                'dropout': 0.3,
                'from': 'lstm4_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.3}},
  'lstm5_fw': { 'L2': 0.001,
                'class': 'rec',
                'direction': 1,
                'dropout': 0.3,
                'from': 'lstm4_pool',
                'n_out': 1024,
                'unit': 'nativelstm2',
                'unit_opts': {'rec_weight_dropout': 0.3}},
  'output': { 'class': 'rec',
              'from': [],
              'max_seq_len': "max_len_from('base:encoder')",
              'target': 'classes',
              'unit': { 'accum_att_weights': { 'class': 'eval',
                                               'eval': 'source(0) + source(1) * source(2) * 0.5',
                                               'from': ['prev:accum_att_weights', 'att_weights', 'base:inv_fertility'],
                                               'out_type': {'dim': 1, 'shape': (None, 1)}},
                        'att': {'axes': 'except_batch', 'class': 'merge_dims', 'from': 'att0'},
                        'att0': {'base': 'base:enc_value', 'class': 'generic_attention', 'weights': 'att_weights'},
                        'att_weights': {'class': 'dropout', 'dropout': 0.3, 'dropout_noise_shape': {'*': None}, 'from': 'att_weights0'},
                        'att_weights0': {'class': 'softmax_over_spatial', 'from': 'energy'},
                        'end': {'class': 'compare', 'from': 'output', 'kind': 'equal', 'value': 0},
                        'energy': {'activation': None, 'class': 'linear', 'from': 'energy_tanh', 'n_out': 1, 'with_bias': False},
                        'energy_in': {'class': 'combine', 'from': ['base:enc_ctx', 'weight_feedback', 's_transformed'], 'kind': 'add', 'n_out': 1024},
                        'energy_tanh': {'activation': 'tanh', 'class': 'activation', 'from': 'energy_in'},
                        'exp_energy': {'activation': 'exp', 'class': 'activation', 'from': 'energy'},
                        'output': {'beam_size': ext_beam_size, 'class': 'choice', 'from': 'output_prob', 'initial_output': 0, 'target': 'classes'},
                        'output_prob': { 'L2': 0.001,
                                         'class': 'softmax',
                                         'dropout': 0.3,
                                         'from': 'readout',
                                         'loss': 'ce',
                                         'loss_opts': {'label_smoothing': 0.1},
                                         'target': 'classes'},
                        'readout': {'class': 'reduce_out', 'from': 'readout_in', 'mode': 'max', 'num_pieces': 2},
                        'readout_in': { 'activation': None,
                                        'class': 'linear',
                                        'from': ['s', 'prev:target_embed', 'att'],
                                        'n_out': 1000,
                                        'with_bias': True},
                        's': { 'class': 'rnn_cell',
                               'from': ['prev:target_embed', 'prev:att'],
                               'n_out': 1000,
                               'unit': 'zoneoutlstm',
                               'unit_opts': {'zoneout_factor_cell': 0.15, 'zoneout_factor_output': 0.05}},
                        's_transformed': {'activation': None, 'class': 'linear', 'from': 's', 'n_out': 1024, 'with_bias': False},
                        'target_embed': {'class': 'dropout', 'dropout': 0.3, 'dropout_noise_shape': {'*': None}, 'from': 'target_embed0'},
                        'target_embed0': { 'activation': None,
                                           'class': 'linear',
                                           'from': 'output',
                                           'initial_output': 0,
                                           'n_out': 621,
                                           'with_bias': False},
                        'weight_feedback': { 'activation': None,
                                             'class': 'linear',
                                             'from': 'prev:accum_att_weights',
                                             'n_out': 1024,
                                             'with_bias': False}}},
  'source': { 'class': 'eval',
              'eval': "self.network.get_config().typed_value('transform')(source(0, as_data=True), network=self.network)",
              'from': 'data'},
  'source0': {'axis': 'F', 'class': 'split_dims', 'dims': (-1, 1), 'from': 'source'}}
newbob_learning_rate_decay = 0.9
newbob_multi_num_epochs = 3
newbob_multi_update_interval = 1
num_epochs = ext_num_epochs
optimizer_epsilon = 1e-08
pretrain = {'construction_algo': custom_construction_algo, 'copy_param_mode': 'subset', 'repetitions': 5}
save_interval = 1
search_output_layer = 'decision'
target = 'classes'
task = 'train'
tf_log_memory_usage = True
tf_log_dir = "tf_log_dir"
train = { 'audio': { 'features': 'mfcc',
             'norm_mean': '<<</path/to/librispeech-100h/stats.mean.txt>>>',
             'norm_std_dev': '<<</path/to/librispeech-100h/stats.std_dev.txt>>>',
             'step_len': 0.01,
             'window_len': 0.025},
  'class': 'OggZipDataset',
  'epoch_wise_filter': {(1, 5): {'max_mean_len': 1000}},
  'partition_epoch': ext_partition_epoch,
  'path': ['<<</path/to/librispeech-100h/train.ogg.zip>>>'],
  'seq_ordering': 'laplace:.1000',
  'targets': { 'bpe_file': '<<</path/to/librispeech-100h/bpe.codes>>>',
               'class': 'BytePairEncoding',
               'seq_postfix': [0],
               'unknown_label': None,
               'vocab_file': '<<</path/to/librispeech-100h/bpe.vocab>>>'},
  'use_cache_manager': True}
truncation = -1
update_on_device = True
use_learning_rate_control_always = True
use_tensorflow = True
window = 1
config = {}

locals().update(**config)


import os
import numpy
from subprocess import check_output, CalledProcessError
from Pretrain import WrapEpochValue
from LmDataset import Lexicon

if ext_data_sample_factor > 1:
    train['path'] = train['path'] * ext_data_sample_factor
    # change of partition epoch happens at sisyphus level

if ext_data_path:
    if not ext_use_baseline_data:
        train["path"] = []
    train["path"] += [ext_data_path]

if ext_decoding:
    task = "search"
    load_epoch = ext_load_epoch
    train = None
    eval = dev
    eval['path'] = ext_eval_zip,
    eval['segment_file'] = None
    max_seq_length = 0
    dev = None

_cf_cache = {}

def cf(filename):
    """Cache manager"""
    if filename in _cf_cache:
        return _cf_cache[filename]
    try:
        cached_fn = check_output(["cf", filename]).strip().decode("utf8")
    except CalledProcessError:
        print("Cache manager: Error occured, using local file")
        return filename
    assert os.path.exists(cached_fn)
    _cf_cache[filename] = cached_fn
    return cached_fn
