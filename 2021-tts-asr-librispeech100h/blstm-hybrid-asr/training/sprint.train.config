[*]
configuration.channel    = output-channel
dot.channel              = nil
encoding                 = UTF-8
error.channel            = output-channel, stderr
log.channel              = output-channel
progress.channel         = output-channel
python-home              = <<<python-env-home>>>
python-program-name      = <<<python-bin>>>
real-time-factor.channel = output-channel
statistics.channel       = output-channel
system-info.channel      = output-channel
time.channel             = output-channel
version.channel          = output-channel
warning.channel          = output-channel, stderr

[*.output-channel]
append     = no
compressed = no
file       = $(LOGFILE)
unbuffered = no

[neural-network-trainer]
action                                             = supervised-training
aligning-feature-extractor.feature-extraction.file = feature.flow
buffer-size                                        = 204800
buffer-type                                        = utterance
class-labels.save-to-file                          = class.labels
estimator                                          = steepest-descent
feature-extraction.file                            = dummy.flow
regression-window-size                             = 5
shuffle                                            = no
silence-weight                                     = 1.0
single-precision                                   = yes
trainer-output-dimension                           = 12001
training-criterion                                 = cross-entropy
weighted-alignment                                 = no
window-size                                        = 1
window-size-derivatives                            = 0

[neural-network-trainer.corpus]
audio-dir                      = <<<LibriSpeech/train-clean-100/>>>
capitalize-transcriptions      = no
file                           = <<</LibriSpeech/corpora/train-clean-100.corpus.gz>>>
progress-indication            = global
segments.file                  = <<<train.segments>>>
warn-about-unexpected-elements = yes

[neural-network-trainer.model-combination.acoustic-model.allophones]
add-all          = no
add-from-file    = <<<allophones>>>
add-from-lexicon = yes

[neural-network-trainer.model-combination.acoustic-model.hmm]
across-word-model   = yes
early-recombination = no
state-repetitions   = 1
states-per-phone    = 3

[neural-network-trainer.model-combination.acoustic-model.state-tying]
file = <<<cart.tree.xml.gz>>>
type = cart

[neural-network-trainer.model-combination.acoustic-model.tdp]
entry-m1.loop = infinity
entry-m2.loop = infinity
scale         = 1.0

[neural-network-trainer.model-combination.acoustic-model.tdp.*]
exit    = 0.0
forward = 0.0
loop    = 3.0
skip    = 30.0

[neural-network-trainer.model-combination.acoustic-model.tdp.silence]
exit    = 20.0
forward = 3.0
loop    = 0.0
skip    = infinity

[neural-network-trainer.model-combination.lexicon]
file                    = <<<lexicon.xml.gz>>>
normalize-pronunciation = yes
